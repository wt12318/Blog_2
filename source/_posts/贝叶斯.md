# 贝叶斯

[Bayes Rules! An Introduction to Applied Bayesian Modeling (bayesrulesbook.com)](https://www.bayesrulesbook.com/)

## Chapter 1 The Big (Bayesian) Picture

> We continuously update our knowledge about the world as we accumulate lived experiences, or  *collect data*

![](https://picgo-wutao.oss-cn-shanghai.aliyuncs.com/undefinedimage-20220907122612-1v71jdt.png)

**Bayesian and frequentist analyses share a common goal: to learn from data about the world around us.**

a, b, b, a 1+3+1+3=8

贝叶斯派和频率派对概率的解释不同：

* 贝叶斯派认为概率是测量事件的**相对合理性**
* 频率派认为概率是可重复事件进行长时间重复之后的**相对频率**

所以在掷硬币的实验中，贝叶斯派的人就会认为正反面是差不多的（物质的性质），而频率派认为如果反复掷一枚硬币，那么有 1/2 的硬币正面朝上。

贝叶斯在构建后验概率的时候实际在平衡先验与数据之间的权重，当数据收集的越来越多，我们的先验知识占的比重就会越来越少。这个对于贝叶斯知识构建也是重要的，当数据收集越来越多，对某一个问题就可能达成共识，即使两个人的先验知识不一样：

![](https://picgo-wutao.oss-cn-shanghai.aliyuncs.com/undefinedimage-20220926162220-tvv2cga.png)

> Specifically, a **Bayesian** analysis assesses the uncertainty of the hypothesis in light of the observed data, and a **frequentist** analysis assesses the uncertainty of the observed data in light of an assumed hypothesis.

**Asking questions**

* A Bayesian hypothesis test seeks to answer: In light of the observed data, what’s the chance that the hypothesis is correct?
* A frequentist hypothesis test seeks to answer: If in fact the hypothesis is incorrect, what’s the chance I’d have observed this, or even more extreme, data?

贝叶斯的假设检验是在观测到数据的情况下，假设是对的概率有多大；而频率派的假设检验是在假设是对的情况下，我们观测到这样或者更极端的数据的概率有多大。

The *reason* the p-value is so commonly misinterpreted is simple – it’s more *natural* to study the uncertainty of a yet-unproven hypothesis (whether you have the rare disease) than the uncertainty of data we have already observed (you tested positive for the rare disease).

## Chapter2 Bayes Rule

**似然：已经发生的事件概率**

P(A|B) 表示已知事件 B 发生时 A 发生的条件概率，但是如果不知道事件 B 是否发生，但是知道 A 已经发生，此时我们可以比较 P(A|B) 和 $P(A|B^c)$ 来得知在不同事件 B 的状态下观测到数据 A 的 **相对似然：**

![](https://picgo-wutao.oss-cn-shanghai.aliyuncs.com/undefinedimage-20221017145705-8j4mu1j.png)

条件概率的引出：两个事件 A,B 的联合概率，也就是 A,B 同时发生的概率可以看成 B 的边缘概率乘以在 B 发生的条件下 A 发生的概率（逻辑，B 发生，然后在 B 发生的条件下 A 发生），因此可以得到 B 发生的条件下 A 发生的 **条件概率：**

$$
P(A|B)=\frac{P(A\cap B)}{P(B)}
$$

我们使用两次条件概率就可以得到贝叶斯定理：

$$
P(B |A) = \frac{P(A \cap B)}{P(A)} = \frac{P(B)L(B|A)}{P(A)}
$$

这里面的 L 就是似然函数，更一般的：

$$
\text{posterior} = \frac{\text{prior } \cdot \text{ likelihood}}{\text{normalizing constant}}
$$

这里的标准化的常数由全概率公式得到（**Law of Total Probability (LTP)**）

代码模拟：

```r
library(bayesrules)
library(tidyverse)
library(janitor)

# Define possible articles
article <- data.frame(type = c("real", "fake"))
# Define the prior model
prior <- c(0.6, 0.4)
set.seed(84735)
article_sim <- sample_n(article, size = 10000, 
                        weight = prior, replace = TRUE)
article_sim <- article_sim %>% 
  mutate(data_model = case_when(type == "fake" ~ 0.2667,
                                type == "real" ~ 0.0222))

glimpse(article_sim)
# Define whether there are exclamation points
data <- c("no", "yes")
# Simulate exclamation point usage 
set.seed(3)
article_sim <- article_sim %>%
  rowwise() %>% 
  mutate(usage = sample(data, size = 1, 
                        prob = c(1 - data_model, data_model)))
article_sim %>% 
  tabyl(usage, type) %>% 
  adorn_totals(c("col","row"))
# usage fake real Total
# no 2961 5833  8794
# yes 1070  136  1206
# Total 4031 5969 10000


article_sim %>% 
  filter(usage == "yes") %>% 
  tabyl(type) %>% 
  adorn_totals("row")
# type    n   percent
# fake 1070 0.8872305
# real  136 0.1127695
# Total 1206 1.0000000
```

### 随机变量的贝叶斯模型

离散概率模型：随机变量有有限个取值，每个取值对应一个概率值，这个对应关系由**概率密度函数**得到（**probability mass function (pmf)**）。

**第一步**根据已有的知识得到一个先验的概率模型，例子：1996 年 Kasparov 和深蓝对战，赢了 3局，平了两局，输了一局，因此构建一个先验模型（假设赢的几率只有三种取值），那么这个先验模型中反映的是 Kasparov 有较大的概率赢下比赛：

![](https://picgo-wutao.oss-cn-shanghai.aliyuncs.com/undefinedimage-20221206163808-w6ol076.png)

‍

**第二步**就是收集处理数据，从而提升对随机变量的理解。Y 是随机变量，表示在 1997 年的比赛中 Kasparov 赢的局数，可以为 1~6 的数字，因此我们需要对 **Y 与 π 的依赖关系建模**，也就是建立一个条件概率模型：

$$
f(y|\pi) = P(Y = y | \pi)
$$

需要做两个假设：

1. 每局游戏之间是独立的，一局的结果并不会影响另一局
2. 赢每一局的概率都是相等的，π

因此这种情况可以使用二项式模型来建模：

$$
Y | \pi \sim \text{Bin}(n,\pi)
$$

在这里就是：

$$
Y | \pi \sim \text{Bin}(6,\pi)
$$

$$
\begin{equation}
f(y|\pi) = \left(\!\begin{array}{c} 6 \\ y \end{array}\!\right) \pi^y (1 - \pi)^{6 - y} \;\; \text{ for } y \in \{0,1,2,3,4,5,6\}  .
\tag{2.8}
\end{equation}
$$

在实际比赛中 Kasparov 只赢了一局，根据这个数据我们可以来更新不同获胜概率的信念，也就是计算似然函数：

$$
L(\pi | y = 1) = f(y=1 | \pi) = \left(\!\begin{array}{c} 6 \\ 1 \end{array}\!\right) \pi^1 (1-\pi)^{6-1} = 6\pi(1-\pi)^5  .
$$

那么这个就是二项式似然函数，可以计算不同获胜概率时的似然函数取值：

![](https://picgo-wutao.oss-cn-shanghai.aliyuncs.com/undefinedimage-20230306221504-n2l0s53.png)

> $L(\cdot | y)$**​**​ ​**provides the tool we need to evaluate the relative **compatibility ​**of data **Y**=**y ​**with various π values.

**第三步**就是计算我们的常数来平衡先验和似然，使用全概率公式：

$$
f(y = 1) = \sum_{\pi \in \{0.2,0.5,0.8\}} L(\pi | y=1) f(\pi)
$$

$$
\begin{equation}
\begin{split}
f(y = 1) 
& = L(\pi = 0.2 | y=1) f(\pi = 0.2) + L(\pi = 0.5 | y=1) f(\pi = 0.5) \\
& \hspace{.2in} + L(\pi = 0.8 | y=1) f(\pi = 0.8) \\
& \approx 0.3932 \cdot 0.10 + 0.0938 \cdot 0.25 + 0.0015 \cdot 0.65 \\
& \approx 0.0637  . \\
\end{split}
\tag{2.9}
\end{equation}
$$

总结：

![](https://picgo-wutao.oss-cn-shanghai.aliyuncs.com/undefinedimage-20230306222733-hmziel2.png)

左边的图是先验，中间的图是似然，右边的图是后验，也就是先验在观测到数据后发生了变化，成了最右边的后验分布。

![](https://picgo-wutao.oss-cn-shanghai.aliyuncs.com/undefinedimage-20230306222823-busv3ht.png)

## Chapter3 The Beta-Binomial Bayesian Model

问题引入：Michelle 要参加大选，收集了 30 次民意调查的结果，以此构建先验模型，注意这里的先验模型不再是上一章中的离散模型，而是连续的模型，其支持率（$\pi$）在 0-1 之间：

![](https://picgo-wutao.oss-cn-shanghai.aliyuncs.com/undefinedimage-20230323083908-q3ttprg.png)

> 连续随机变量的概率密度函数可以大于一，在某个随机变量的取值下的概率密度函数值可以大于1，因此表示的一个相对的概念

### Beta 模型介绍 -- 先验模型

如果 $\pi$ 是 0-1 上的随机变量，那么 $\pi$ 的不确定性可以由 beta 模型来建模，超参数是 $\alpha$ 和 $\beta$：

$$
\pi \sim \text{Beta}(\alpha, \beta).
$$

其概率密度函数为：

$$
f(\pi) = \frac{\Gamma(\alpha + \beta)}{\Gamma(\alpha)\Gamma(\beta)} \pi^{\alpha-1} (1-\pi)^{\beta-1} \;\; \text{ for } \pi \in [0,1] \tag{3.1}
$$

$$
\Gamma(z) = \int_0^\infty x^{z-1}e^{-y}dx
$$

不同的 $\alpha$ 和 $\beta$ 下，概率密度函数的形状也不同：

![](https://picgo-wutao.oss-cn-shanghai.aliyuncs.com/undefinedimage-20230323090022-iwetng8.png)

beta 模型的一些性质：

* $$
  \begin{equation}
  \begin{split}
  E(\pi) & = \frac{\alpha}{\alpha + \beta} \\
  \text{Mode}(\pi) & = \frac{\alpha - 1}{\alpha + \beta - 2} \;\;\; \text{ when } \; \alpha, \beta > 1. \\
  \end{split}
  \tag{3.2}
  \end{equation}
  $$

* $$
  \begin{equation}
  \text{Var}(\pi) = \frac{\alpha \beta}{(\alpha + \beta)^2(\alpha + \beta + 1)} .
  \tag{3.3}
  \end{equation}
  $$

现在我们可以为之前的民意调查选择一个先验的模型了（通过调节 $\alpha$ 和 $\beta$），通过观察发现，均值大概在 0.45 左右，也就是：

‍

$$
\frac{\alpha}{\alpha+ \beta}\approx0.45
$$

可以尝试 Beta(9,11), Beta(27,33), Beta(45,55)，发现 45 和 55 比较符合：

```r
plot_beta(45, 55)
```

![](https://picgo-wutao.oss-cn-shanghai.aliyuncs.com/undefinedimage-20230324103110-7t8szk7.png)

### 二项式数据以及似然函数 -- 收集数据

贝叶斯分析的第二个步骤就是收集一些新的数据，这里做了 50 次新的民意调查，支持人数为随机变量 Y，假设：

* 每次投票是独立的
* 每次投票支持 Michelle 的概率都是 $\pi$​

因此随机变量 Y 服从二项分布：

$$
Y | \pi \sim \text{Bin}(50, \pi)
$$

我们可以得到 Y 关于 $\pi$ 的似然函数：

![](https://picgo-wutao.oss-cn-shanghai.aliyuncs.com/undefinedimage-20230324111010-4quts4d.png)

### Beta 后验模型 -- 更新

基于我们的先验模型和收集的数据（50 次里面有 30 次支持），我们可以得到后验模型：

![](https://picgo-wutao.oss-cn-shanghai.aliyuncs.com/undefinedimage-20230324140231-ohl271i.png)

根据贝叶斯定理可以得到：

$$
f(\pi | y = 30) = \frac{f(\pi)L(\pi|y = 30)}{f(y = 30)}.
$$

分母是一个标准化的因子，因此可以不纳入计算，然后代入先验的 beta 分布和数据的二项分布：

$$
\begin{split}
f(\pi | y = 30)
& \propto f(\pi) L(\pi | y=30)  \\
& = \frac{\Gamma(100)}{\Gamma(45)\Gamma(55)}\pi^{44}(1-\pi)^{54} \cdot \left(\!\!\begin{array}{c} 50 \\ 30 \end{array}\!\!\right) \pi^{30} (1-\pi)^{20}  \\
& = \left[\frac{\Gamma(100)}{\Gamma(45)\Gamma(55)}\left(\!\!\begin{array}{c} 50 \\ 30 \end{array}\!\!\right) \right] \cdot \pi^{74} (1-\pi)^{74}  \\
& \propto \pi^{74} (1-\pi)^{74}  . \\
\end{split}
$$

这里面的 $\pi^{74} (1-\pi)^{74}$ 叫做概率密度函数的 **kernel ，**并且这个和 Beta(75,75) 的 kernel 是一样的：

$$
Beta(75,75) = \frac{\Gamma(150)}{\Gamma(75)\Gamma(75)} \pi^{74} (1-\pi)^{74} \propto \pi^{74} (1-\pi)^{74}  .
$$

因此后验分布服从 $\alpha$ = 75，$\beta$ = 75 的 Beta 分布。**这种后验分布和先验分布是一个分布家族的**，我们称这个 Beta 模型是相应的二项模型的共轭先验（**Conjugate prior**）。

> We say that **f**(**π)** is a conjugate prior for **L**(**π**|**y**) if the posterior, **f**(**π**|**y**)**∝**f**(**π**)**L**(**π**|**y**)**, is from the same model family as the prior.

### Beta-Binomial 模型

上面的是一种最基础的 Beta-Binomial 模型，由先验的 beta 模型和数据的 Binomial 模型构成；一般的 Beta-Binomial ：

$$
\begin{split}
Y | \pi & \sim \text{Bin}(n, \pi) \\
\pi & \sim \text{Beta}(\alpha, \beta). \\
\end{split}
$$

在 n 次实验中观测到 Y=y 次成功的数据后，$\pi$ 的后验可以由一个 Beta 模型来描述，反映了先验（参数是 $\alpha$ 和 $\beta$）和数据的影响：

$$
\begin{equation}
\pi | (Y = y) \sim \text{Beta}(\alpha + y, \beta + n - y)  .
\tag{3.10}
\end{equation}
$$

得到这个的过程和上面类似：

$$
\begin{equation}
f(\pi) = \frac{\Gamma(\alpha + \beta)}{\Gamma(\alpha)\Gamma(\beta)}\pi^{\alpha - 1}(1-\pi)^{\beta - 1} 
\;\; \text{ and } \;\; 
L(\pi|y) = \left(\!\!\begin{array}{c} n \\ y \end{array}\!\!\right) \pi^{y} (1-\pi)^{n-y}  .
\tag{3.12}
\end{equation}
$$

$$
\begin{split}
f(\pi | y)
& \propto f(\pi)L(\pi|y) \\
& = \frac{\Gamma(\alpha + \beta)}{\Gamma(\alpha)\Gamma(\beta)}\pi^{\alpha - 1}(1-\pi)^{\beta - 1}  \cdot \left(\!\begin{array}{c} n \\ y \end{array}\!\right) \pi^{y} (1-\pi)^{n-y} \\
& \propto \pi^{(\alpha + y) - 1} (1-\pi)^{(\beta + n - y) - 1}  .\\
\end{split}
$$

我们可以来做一些模拟：使用 `rbeta()`​ 从 Beta 分布随机抽取 10000 个 $\pi$ 值，然后对每个 $\pi$ 使用 `rbinom()`​从二项分布随机抽取 10000 个 Y：

```r
set.seed(84735)
michelle_sim <- data.frame(pi = rbeta(10000, 45, 55)) %>% 
  mutate(y = rbinom(10000, size = 50, prob = pi))

ggplot(michelle_sim, aes(x = pi, y = y)) + 
  geom_point(aes(color = (y == 30)), size = 0.1)
```

![](https://picgo-wutao.oss-cn-shanghai.aliyuncs.com/undefinedimage-20230324143646-6qmi239.png)

然后对于 Y = 30，我们可以展示在不同的 $\pi$ 下的密度：

```r
# Keep only the simulated pairs that match our data
michelle_posterior <- michelle_sim %>% 
  filter(y == 30)

# Plot the remaining pi values
ggplot(michelle_posterior, aes(x = pi)) + 
  geom_density()
```

![](https://picgo-wutao.oss-cn-shanghai.aliyuncs.com/undefinedimage-20230324143813-8dv5dtz.png)

可以看到这个和后验的 Beta(75,75) 分布是很接近的。

总结：这一章主要讲了 Beta-Binomial 模型：

$$
\begin{split}
Y | \pi & \sim \text{Bin}(n, \pi) \\
\pi & \sim \text{Beta}(\alpha, \beta) \\
\end{split} \;\; \Rightarrow \;\; 
\pi | (Y = y) \sim \text{Beta}(\alpha + y, \beta + n - y)  .
$$

这个模型反映了贝叶斯数据分析的一般的四个步骤：

1. 先验模型，通过调节 Beta 模型的 $\alpha$ 和 $\beta$ 的超参数来反映 $\pi$ 的可能性
2. 数据模型，n 次独立实验中成功的次数，服从二项分布
3. 似然函数，依据实际观测到的数据，代入数据模型，得到似然函数（二项分布概率密度函数），反映了不同 $\pi$ 和数据的相容性
4. 后验模型，通过贝叶斯定律，结合共轭的 Beta 先验和二项数据分布，得到后验的 Beta 模型

## Chapter 4 贝叶斯分析中的平衡和顺序性

问题引入：电影中的女性形象的 Bechdel test，如果一个电影符合下面三个标准即通过该检验：

* 至少有两个女性角色
* 两个女性角色之间相互交谈
* 谈论的内容和男性无关

设 $\pi$ 为通过检验的电影占比，有三个人分别代表着女性主义者，中立主义者和乐观主义者，对这个 $\pi$ 有着各种的先验观念，我们可以使用 β 模型（通过调整不同的 α 和 β 参数）来对他们的先验观念进行建模：

![](https://picgo-wutao.oss-cn-shanghai.aliyuncs.com/undefinedch4-bechdel-priors-1-20230702163610-m8xsime.png)

先验分布的变异性（variability）反应了对先验信息的确定程度，越不确定，变异程度就越大，比如中立主义者的均匀分布，这类先验称为模糊先验（**Vague prior**）；而乐观主义者则对其先验信息非常确定，我们将这类先验称为有信息的先验（**Informative prior**）。

### 不同的先验--不同的后验

现在收集一些新数据：记录最近的 n 个电影中通过 Bechdel test 的个数 Y，因此这个数据服从参数为 $\pi$ 的二项分布，参数为 α 和 β 的 Beta 二项分布：

$$
\begin{split}
Y | \pi & \sim \text{Bin}(n, \pi)  \\
\pi & \sim \text{Beta}(\alpha, \beta) \\ 
\end{split}
$$

因此可以得到独特的 π 后验模型，取决于独特的先验分布（通过α和β）和共同的观察数据（通过y和n）：

$$
\pi | (Y = y) \sim \text{Beta}(\alpha + y, \beta + n - y)
$$

```R
##导入数据
data(bechdel, package = "bayesrules")

#随机抽样20个电影
set.seed(84735)
bechdel_20 <- bechdel %>% 
  sample_n(20)

bechdel_20 %>% 
  head(3)
##binary 变量表示该电影是否通过测试
# A tibble: 3 x 3
   year title      binary
  <dbl> <chr>      <chr> 
1  2005 King Kong  FAIL  
2  1983 Flashdance PASS  
3  2013 The Purge  FAIL  

bechdel_20 %>% 
  tabyl(binary) %>% 
  adorn_totals("row")
 binary  n percent
   FAIL 11    0.55
   PASS  9    0.45
  Total 20    1.00
###9 个电影通过了测验
```

可以根据上面的式子算出各自的后验分布：

|Analyst|Prior|Posterior|
| ----------| ------------| -------------|
|女性主义|Beta(5,11)|Beta(14,22)|
|中立主义|Beta(1,1)|Beta(10,12)|
|乐观主义|Beta(14,1)|Beta(23,12)|

![](https://picgo-wutao.oss-cn-shanghai.aliyuncs.com/undefinedbechdel-post-ch4-1-20230702165613-2yb2ymj.png)

可以看到对于中立主义者来说其先验分布没有任何信息，因此其后验分布和似然是一致的。

### 不同的数据--不同的后验

现在来实验下不同的数据对后验的影响，假设先验分布都是上面的乐观主义者的先验，但是收集的数据不同：

```R
bechdel %>% 
  filter(year == 1991) %>% 
  tabyl(binary) %>% 
  adorn_totals("row")
 binary  n percent
   FAIL  7  0.5385
   PASS  6  0.4615
  Total 13  1.0000

bechdel %>% 
  filter(year == 2000) %>% 
  tabyl(binary) %>% 
  adorn_totals("row")
 binary  n percent
   FAIL 34  0.5397
   PASS 29  0.4603
  Total 63  1.0000

bechdel %>% 
  filter(year == 2013) %>% 
  tabyl(binary) %>% 
  adorn_totals("row")
 binary  n percent
   FAIL 53  0.5354
   PASS 46  0.4646
  Total 99  1.0000
```

![](https://picgo-wutao.oss-cn-shanghai.aliyuncs.com/undefinedbechdel-data-ch4-1-20230702171041-3j50vl0.png)

|数据|后验|
| --------| -------------|
|**Y**=**6** of **n**=**13**|Beta(20,8)|
|**Y**=**29** of **n**=**63**|Beta(43,35)|
|**Y**=**46** of **n**=**99**|Beta(60,54)|

可以看到数据量越大（虽然这些数据中通过检验的比例是相同的，46%）后验分布就越接近似然函数，数据对后验的影响也就越大。

### 在先验和数据之间平衡

数据和先验对后验的影响可以用下图来总结：

![](https://picgo-wutao.oss-cn-shanghai.aliyuncs.com/undefinedbechdel-combined-ch4-1-20230702172233-67e3f3u.png)

* 数据量越大，后验分布越接近似然函数，先验分布对后验分布的影响越小（从左到右）
* 先验含有的信息越多，对后验的影响越大（从上到下）
* 注意最后一列，当数据量足够大时，不管什么先验分布都可以得到相同的后验分布

> 但是我们需要注意，当先验选择的不恰当时也会出现无论多大的数据也无法消除先验影响的情况。比如先验分布为 :
>
> $$
> \pi \sim \text{Unif}(0,0.25)
> $$
>
> $$
> f(\pi) = 4 \; \text{ for } \pi \in [0, 0.25]
> $$
>
> 后验分布：
>
> $$
> \begin{split}
> f(\pi | y=8) 
> & \propto f(\pi)L(\pi | y=8) \\
> & = 4 \cdot \left(\!\begin{array}{c} 10 \\ 8 \end{array}\!\right) \ \pi^{8} (1-\pi)^{2} \\
> & \propto \pi^{8} (1-\pi)^{2}. \\
> \end{split}
> $$
>
> ![](https://picgo-wutao.oss-cn-shanghai.aliyuncs.com/undefinedimage-20230702211858-gqzc0ho.png)

这个结论我们可以通过推导得到：

对于上面的后验模型，我们可以计算其 beta 分布的均值：

$$
E(\pi|Y=y)=\frac{\alpha+y}{\alpha + \beta +n}
$$

可以将这个式子重写成先验和数据的组合：

$$
\begin{split}
E(\pi | Y=y)  
& = \frac{\alpha}{\alpha + \beta + n} + \frac{y}{\alpha + \beta + n}  \\
& = \frac{\alpha}{\alpha + \beta + n}\cdot\frac{\alpha + \beta}{\alpha + \beta} + \frac{y}{\alpha + \beta + n}\cdot\frac{n}{n}  \\
& = \frac{\alpha + \beta}{\alpha + \beta + n}\cdot\frac{\alpha}{\alpha + \beta} + \frac{n}{\alpha + \beta + n}\cdot\frac{y}{n}  \\
& = \frac{\alpha + \beta}{\alpha + \beta + n}\cdot E(\pi) + \frac{n}{\alpha + \beta + n}\cdot\frac{y}{n}  .  \\
\end{split}
$$

因此后验的均值可以看成是先验均值和数据（样本）成功率的**加权平均，**这个权重的和也是 1；我们可以以上面表的第一行和最后一行为例：

$$
\begin{split}
E(\pi | Y=6)  
& = \frac{14 + 1}{14 + 1 + 13} \cdot E(\pi) + \frac{13}{14 + 1 + 13}\cdot\frac{y}{n} \\
& = 0.5357 \cdot \frac{14}{15} + 0.4643 \cdot \frac{6}{13}   \\
& = 0.7143  .  \\
\end{split}
$$

$$
\begin{split}
E(\pi | Y=46)  
& = \frac{14 + 1}{14 + 1 + 99} \cdot E(\pi) + \frac{99}{14 + 1 + 99}\cdot\frac{y}{n} \\
& = 0.1316 \cdot \frac{14}{15} + 0.8684 \cdot \frac{46}{99}   \\
& = 0.5263  .  \\
\end{split}
$$

尽管先验的均值是一样的（14/15），样本的成功率也差不多（46%），但是由于数据量的不同造成了先验和数据的权重的差别；实际上当 n 趋向于无穷大的时候，先验均值的权重趋向于 0，而数据的权重趋向于 1。因此当收集的数据越来越多，后验模型会越来越倾向于数据而不是先验。这个越来越多就反映了序贯贝叶斯分析或者叫做贝叶斯学习：

> In a sequential Bayesian analysis, a posterior model is updated  incrementally as more data come in. With each new piece of data, the  previous posterior model reflecting our understanding prior to observing  this data becomes the new prior model.

序贯分析有两个基本性质：

1. 最终得到的结果和数据的收集次序无关
2. 最终的后验结果只依赖于累积的数据（一步收集也行）

设 $\theta$ 是先验分布的参数，两个时间点分别收集的数据为 $y_1$ 和 $y_2$ ，那么：

$$
f(\theta | y_1,y_2) = f(\theta|y_2,y_1)
$$

‍

## Chapter 5

在选择先验模型的时候需要考虑的：

* 计算简便性：特别是当我们可用的算力不够时，一个易于计算的后验模型是有利的
* 可解释性

前面使用过的 Beta-Binomial 模型是满足这些标准的: 首先已知先验 Beta 模型的参数（$\alpha$ 和 $\beta$）以及二项分布的数据（Y=y），可以简单地得到后验分布：Beta($\alpha$ + y, $\beta$ + n - y)；其次后验模型通过 y 和 n 的值反映了数据相对于先验分布 α 和 β 的影响。如果 α 和 β 相对于样本量 n 较大，那么后验就会较大地偏离先验，然而，如果样本量n 相对于 α 和 β 较大，那么数据对后验的影响将超过先验。在第三章已经讲过这个 Beta-Binomial 属于共轭家族，更一般的定义：

> 设有着参数 $\theta$ 的先验模型的概率密度函数为 $f(\theta)$，以 $\theta$ 为条件的数据 Y 的模型的似然函数为 $L(\theta | y)$；如果后验模型的 PDF $f(\theta |y) \propto f(\theta)L(\theta | y)$ 是和先验是同一个模型家族的，那么这个先验就是共轭先验

### Gamma-Poisson 共轭家族

问题引入：设 $\lambda$ 为每天收到的诈骗电话的数量（比率 rate）；收集的数据为 n 天中每天诈骗电话的数量。这个问题就不能用前面的 Beta-二项分布模型来建模了，因为这个 $\lambda$ 可以取任意的正数，不局限在 0-1 之间，其次数据 Y 也可以取任意的非负整数，不必要小于实验次数 n。对于这个数据 Y ，可以使用泊松模型来建模：

> 设随机变量 Y 为独立事件在一定时间或空间中发生的次数，$\lambda$ 为这些事件发生的比率（可以理解为平均发生率），那么 Y 就服从参数为 $\lambda$ 的泊松分布：
>
> $$
> Y | \lambda \sim \text{Pois}(\lambda).
> $$
>
> 其概率质量函数（PMF）为：
>
> $$
> f(y|\lambda) =  \frac{\lambda^y e^{-\lambda}}{y!}\;\; \text{ for } y \in \{0,1,2,\ldots\}
> $$
>
> 泊松分布的期望和方差都是 $\lambda$

对于每天的诈骗电话数据可以表示为：

$$
f(y_i|\lambda) =  \frac{\lambda^{y_i}e^{-\lambda}}{y_i!}\;\; \text{ for } y_i \in \{0,1,2,\ldots\}  .
$$

根据独立事件的概率累乘规则，n 天的联合概率质量函数为（即得到 n 天的诈骗电话数量的序列的概率）：

$$
f(\vec{y} | \lambda) = \prod_{i=1}^{n}f(y_i | \lambda) = \prod_{i=1}^{n}\frac{\lambda^{y_i}e^{-\lambda}}{y_i!}
$$

<img src="https://picgo-wutao.oss-cn-shanghai.aliyuncs.com/image-20230719094906984.png" style="zoom:67%;" />

将其改写一下：
$$
\begin{split}
f(\vec{y} | \lambda) 
& = \frac{\lambda^{y_1}e^{-\lambda}}{y_1!} \cdot \frac{\lambda^{y_2}e^{-\lambda}}{y_2!} \cdots \frac{\lambda^{y_n}e^{-\lambda}}{y_n!} \\
& = \frac{\left[\lambda^{y_1}\lambda^{y_2} \cdots \lambda^{y_n}\right] \left[e^{-\lambda}e^{-\lambda} \cdots e^{-\lambda}\right]}{y_1! y_2! \cdots y_n!} \\
& =\frac{\lambda^{\sum y_i}e^{-n\lambda}}{\prod_{i=1}^n y_i!} \\
\end{split}
$$

<img src="https://picgo-wutao.oss-cn-shanghai.aliyuncs.com/image-20230719095020936.png" style="zoom:67%;" />

可以得到泊松**似然函数**（分母是常数）：
$$
L(\lambda | \vec{y}) = \frac{\lambda^{\sum y_i}e^{-n\lambda}}{\prod_{i=1}^n y_i!} \propto \lambda^{\sum y_i}e^{-n\lambda} \;\; \text{ for } \lambda > 0.
$$

<img src="https://picgo-wutao.oss-cn-shanghai.aliyuncs.com/image-20230719095053852.png" style="zoom:67%;" />

现在我们有了数据的模型，要得到后验模型还需要对先验参数 $\lambda$ 进行建模；先验知识为，大概每天有 5 个诈骗电话，可能浮动的范围在 2 到 7 之间。因此这个 $\lambda$ 是大于 0 的正数，有着这种特征的概率模型有很多，比如 F，Weibull 和 Gamma，我们这里关注 Gamma 模型。

> Gamma 和指数模型
>
> 设 $\lambda$ 为连续随机变量，可以取任意的正数，也就是 $\lambda$ > 0；$\lambda$ 的变异性可以用 Gamma 模型建模，Gamma 模型有着形状参数 s > 0 和速率参数（？）r > 0:
>
> $$
> \lambda \sim \text{Gamma}(s, r)  .
> $$
>
> Gamma 模型的 PDF 为：
>
> $$
> f(\lambda) = \frac{r^s}{\Gamma(s)} \lambda^{s-1} e^{-r\lambda} \;\; \text{ for } \lambda > 0.
> $$
>
> 期望，众数和方差为：
>
> $$
> \begin{split}
> E(\lambda) & = \frac{s}{r} \\
> \text{Mode}(\lambda) & = \frac{s - 1}{r} \;\; \text{ for } s \ge 1 \\
> \text{Var}(\lambda) & = \frac{s}{r^2}. \\
> \end{split}
> $$
>
> 另外指数模型是 Gamma 模型的特例，也就是 s = 1 时的 Gamma 模型

因此我们想要选择合适的 s 和 r 来反映 $\lambda$ 的模式，首先均值为 5，也就是 s/r 为 5，$s=5r$，大部分的取值应该在 2 ~ 7 之间，通过 `plot_gamma()`​函数（`bayesrules`​ 包）可以进行一些实验：

```R
library(bayesrules)
library(ggplot2)

res <- vector("list",9)
for (i in 1:9){
  p <- plot_gamma(i*5,i,mean=T)+
    geom_vline(xintercept=2, linetype="dashed", color = "red",size=1)+
    geom_vline(xintercept=7, linetype="dashed", color = "red",size=1)+
    labs(title = paste0("s = ",i*5," r = ",i))+
    theme_bw()
  res[[i]] <- p
}
library(patchwork)  
wrap_plots(res,guides = "collect")
ggsave("D:/s_r_bayes.pdf",width = 16,height = 10)
```

![](https://picgo-wutao.oss-cn-shanghai.aliyuncs.com/s_r_bayes_00-20230715143815-g2yqezo.png)

可以看到 s = 10，r = 2 是一个不错的选择：

$$
\lambda \sim \text{Gamma}(10,2)
$$

$$
f(\lambda) =  \frac{2^{10}}{\Gamma(10)} \lambda^{10-1} e^{-2\lambda} \;\; \text{ for } \lambda > 0.
$$

现在有了先验和数据，我们就可以根据贝叶斯公式得到后验模型：

$$
f(\lambda|\vec{y}) \propto f(\lambda)L(\lambda|\vec{y}) = \frac{r^s}{\Gamma(s)} \lambda^{s-1} e^{-r\lambda} \cdot \frac{\lambda^{\sum y_i}e^{-n\lambda}}{\prod y_i!} \;\;\; \text{ for } \lambda > 0.
$$

去掉和参数 $\lambda$ 无关的常数项：

$$
\begin{split} 
f(\lambda|\vec{y}) 
& \propto \lambda^{s-1} e^{-r\lambda} \cdot \lambda^{\sum y_i}e^{-n\lambda} \\
& = \lambda^{s + \sum  y_i - 1} e^{-(r+n)\lambda} \\
\end{split}
$$

这个后验模型 PDF 的核就是 Gamma 模型的 PDF，形状参数 s 为 $s + \sum y_i$，速率参数 r 为 $r + n$ ，因此：

$$
\lambda|\vec{y} \;  \sim \; \text{Gamma}\bigg(s + \sum  y_i, r + n \bigg)  .
$$

> Gamma-Poisson 模型
>
> 设 $\lambda$ >0 为未知的速率参数，$(Y_1,Y_2,...,Y_n)$ 为独立的 $Pois(\lambda)$ 样本，Gamma-Poisson 贝叶斯模型：
>
> $$
> \begin{split}
> Y_i | \lambda & \stackrel{ind}{\sim} \text{Pois}(\lambda) \\
> \lambda & \sim \text{Gamma}(s, r) .\\
> \end{split}
> $$
>
> 当观测到数据 $\vec{y} = (y_1,y_2,y_n)$ ，$\lambda$ 的后验模型也是一个 Gamma 模型：
>
> $$
> \lambda|\vec{y} \; \sim \; \text{Gamma}\left(s + \sum y_i, \; r + n\right)
> $$

比如我们现在收集了 4 天的诈骗电话数据为：**(**6**,**2**,**2**,**1**)，**也就是 $n = 4, \sum y_i = 11$，可以使用 `plot_gamma_poisson`​ 函数将先验，数据似然和后验展示在一张图中：

```R
plot_gamma_poisson(shape = 10, rate = 2, sum_y = 11, n = 4)
```

![](https://picgo-wutao.oss-cn-shanghai.aliyuncs.com/image-20230715151009-u4yu04z.png)

> **后验均值将始终介于先验均值和数据均值之间**，如果后验均值不在这个范围说明中间哪个步骤出现了错误，需要排查

### 正态-正态共轭家族

问题引入：在有脑震荡史的人群中，我们对海马体的平均容积 $\mu$ 感兴趣；从维基百科上搜索得到对成年人来说两侧海马体的总容积在 6 ~7 立方厘米，这个信息可以作为先验知识，收集了 25 个有着脑震荡史的人的海马体容积数据 $(Y_1,Y_2,...,Y_n)$ 将使用正态-正态贝叶斯模型来对后验进行建模（通常来说生物相关的测量数据是对称分布的，因此使用正态模型是合理的）。

> 正态模型
>
> 设 Y 为一个连续随机变量，取值可以为 $-\infty$ 到 $\infty$，Y 可以由均值参数 $\mu$ 和标准差参数 $\sigma$ 定义的正态模型来建模：
>
> $$
> Y \sim N(\mu, \sigma^2).
> $$
>
> 其 PDF 为：
>
> $$
> f(y) = \frac{1}{\sqrt{2\pi\sigma^2}} \exp\bigg[{-\frac{(y-\mu)^2}{2\sigma^2}}\bigg] \;\; \text{ for } y \in (-\infty,\infty)
> $$
>
> 期望，众数，方差和标准差为：
>
> $$
> \begin{split}
> E(Y) & = \text{ Mode}(Y) = \mu \\
> \text{Var}(Y) & = \sigma^2 \\
> \text{SD}(Y) & = \sigma. \\
> \end{split}
> $$

为了方便起见，我们设正态分布的标准差已知为 0.5，也就是大部分人的海马体体积在均值附近两个标准差也就是 1 立方厘米范围内波动，因此：

$$
Y_i|\mu \sim N(\mu,\sigma^2)
$$

> **Reasonable doesn’t mean perfect. ​**In general, not letting *perfect* be the enemy of *good* will be a theme throughout this book (mainly because there is no perfect).

因此数据的联合 PDF 为独立事件的乘积，也就是数据的正态似然函数：

$$
f(\vec{y} | \mu) = \prod_{i=1}^{n}f(y_i|\mu) = \prod_{i=1}^{n}\frac{1}{\sqrt{2\pi\sigma^2}} \exp\bigg[{-\frac{(y_i-\mu)^2}{2\sigma^2}}\bigg]  .
$$

<img src="https://picgo-wutao.oss-cn-shanghai.aliyuncs.com/image-20230719095143856.png" style="zoom:67%;" />

由于 $\sigma$ 是已知的，我们可以和之前处理的步骤一样将常数项丢掉，写成比例的形式：
$$
L(\mu |\vec{y}) \propto \prod_{i=1}^{n} \exp\bigg[{-\frac{(y_i-\mu)^2}{2\sigma^2}}\bigg] =  \exp\bigg[{-\frac{\sum_{i=1}^n(y_i-\mu)^2}{2\sigma^2}}\bigg]  .
$$

<img src="https://picgo-wutao.oss-cn-shanghai.aliyuncs.com/image-20230719095216175.png" style="zoom:67%;" />

重写后得到（所有和 $\mu$ 无关的都可以当作常数项舍弃）与样本均值和样本量相关的似然函数：
$$
L(\mu | \vec{y}) \propto \exp\bigg[{-\frac{(\bar{y}-\mu)^2}{2\sigma^2/n}}\bigg] \;\;\;\; \text{ for } \; \mu \in (-\infty, \infty).
$$

有了数据的似然之后，我们还需要考虑参数 $\mu$ 的先验模型，由于$\mu$ 可以取 $(-\infty, \infty)$ ,因此使用一个正态的先验也是一个合理的选择：

$$
\mu \sim N(\theta, \tau^2)
$$

$$
f(\mu) = \frac{1}{\sqrt{2\pi\tau^2}} \exp\bigg[{-\frac{(\mu - \theta)^2}{2\tau^2}}\bigg] \;\; \text{ for } \mu \in (-\infty,\infty)  .
$$

根据之前搜集的信息海马体的体积在 6~7 立方厘米，因此可以将 $\theta$ 设置为 6.5，$\tau$ 设置为 0.4 （6.5 +- 2*0.4 = 5.7 ~ 7.3 之间，与数据较相符）：

```R
plot_normal(mean = 6.5, sd = 0.4)
```

![](https://picgo-wutao.oss-cn-shanghai.aliyuncs.com/image-20230718201250-ivibg8f.png)

接下来我们就可以运用贝叶斯规则得到后验模型：

$$
f(\mu|\vec{y}) \propto f(\mu)L(\mu|\vec{y}) \propto \exp\bigg[{\frac{-(\mu - \theta)^2}{2\tau^2}}\bigg] \cdot \exp\bigg[{-\frac{(\bar{y}-\mu)^2}{2\sigma^2/n}}\bigg]  .
$$

$$
\begin{split}
f(\mu|\vec{y}) 
& \propto  \exp\Bigg[{\frac{-\mu^2+2\mu\theta-\theta^2}{2\tau^2}}\Bigg]\exp\Bigg[{\frac{-\mu^2+2\mu\bar{y}-\bar{y}^2}{2\sigma^2/n}}\Bigg] \\
& \propto  \exp\Bigg[{\frac{-\mu^2+2\mu\theta}{2\tau^2}}\Bigg]\exp\Bigg[{\frac{-\mu^2+2\mu\bar{y}}{2\sigma^2/n}}\Bigg]. \\
\end{split}
$$

$$
\begin{split}
f(\mu|\vec{y}) 
& \propto  \exp\Bigg[{\frac{(-\mu^2+2\mu\theta)\sigma^2/n}{2\tau^2\sigma^2/n}}\Bigg]\exp\Bigg[{\frac{(-\mu^2+2\mu\bar{y})\tau^2}{2\tau^2\sigma^2/n}}\Bigg] \\
& \propto  \exp\Bigg[{\frac{(-\mu^2+2\mu\theta)\sigma^2 +(-\mu^2+2\mu\bar{y})n\tau^2}{2\tau^2\sigma^2}}\Bigg]. \\
\end{split}
$$

$$
\begin{split}
f(\mu|\vec{y}) 
& \propto  \exp\Bigg[{\frac{-\mu^2(n\tau^2+\sigma^2)+2\mu(\theta\sigma^2+ \bar{y}n\tau^2) }{2\tau^2\sigma^2}}\Bigg] \\
& \propto  \exp\Bigg[{\frac{-\mu^2+2\mu\left(\frac{\theta\sigma^2 + \bar{y}n\tau^2}{n\tau^2+\sigma^2}\right) }{2(\tau^2\sigma^2) /(n\tau^2+\sigma^2)}}\Bigg]. \\
\end{split}
$$

所有和 $\mu$ 无关的都可以当作常数项丢弃：

$$
\begin{split}
f(\mu|\vec{y}) 
& \propto  \exp\Bigg[{\frac{-\bigg(\mu - \frac{\theta\sigma^2 + \bar{y}n\tau^2}{n\tau^2+\sigma^2}\bigg)^2 }{2(\tau^2\sigma^2) /(n\tau^2+\sigma^2)}}\Bigg]. \\
\end{split}
$$

和正态分布的 PDF 对比，得到：

$$
\mu|\vec{y} \;  \sim  \; N\left(\frac{\theta\sigma^2+ \bar{y}n\tau^2}{n\tau^2+\sigma^2}, \;{\frac{\tau^2\sigma^2}{n\tau^2+\sigma^2}} \right)
$$

> 正态-正态贝叶斯模型
>
> 设 $\mu$ 为为止的均值参数可以取 $(-\infty, \infty)$，$(Y_1,...Y_n)$ 为来自参数为 $\mu$ 和 $\sigma$ 的正态分布的独立样本，其中 $\sigma$ 参数已知，正态-正态贝叶斯模型：
>
> $$
> \begin{split}
> Y_i | \mu & \stackrel{ind}{\sim} N(\mu, \sigma^2) \\
> \mu & \sim N(\theta, \tau^2) \\
> \end{split}
> $$
>
> 观测数据为：
>
> $$
> \vec{y} = (y_1,y_2,\ldots,y_n)
> $$
>
> 其均值为 $\bar y$，那么 $\mu$ 的后验模型仍然是正态模型：
>
> $$
> \mu|\vec{y} \; \sim \;  N\bigg(\theta\frac{\sigma^2}{n\tau^2+\sigma^2} + \bar{y}\frac{n\tau^2}{n\tau^2+\sigma^2}, \; \frac{\tau^2\sigma^2}{n\tau^2+\sigma^2}\bigg)  .
> $$

可以看到后验的均值是先验均值和数据样本均值的加权平均，后验的方差是由先验方差和数据方差组合而成，二者都受样本量 n 的影响；当 n 增加时，后验均值中先验均值的权重就会变小而数据的权重就会变大

$$
\frac{\sigma^2}{n\tau^2+\sigma^2} \to 0 
\;\; \text{ and } \;\;
\frac{n\tau^2}{n\tau^2+\sigma^2} \to 1 .
$$

n 增加时后验的方差也会减小，因此当数据越来越多时我们对 $\mu$ 就越确定，后验和数据就越一致，这和前面讲到的其他模型是一样的。

例子：在上面我们已经建立了关于 $\mu$ 的先验模型：$u \sim N(6.5,0.4^2)$ ，现在考虑实际的数据，在 bayesrules 包中的 `football`​ 数据内有 75 个对象的海马体体积的研究：25 个有个脑震荡史的足球运动员，25 个没有脑震荡史的足球运动员以及 25 个对照，我们关注的是有脑震荡史的人群：

```R
# Load the data
data(football)
concussion_subjects <- football %>%
  filter(group == "fb_concuss")

concussion_subjects %>%
  summarize(mean(volume))

#  mean(volume)
#1       5.7346
```

均值是 5.7346，查看数据的分布：

```R
ggplot(concussion_subjects, aes(x = volume)) + 
  geom_density()+
  theme_bw()
```

![](https://picgo-wutao.oss-cn-shanghai.aliyuncs.com/image-20230719090557-j9zicwg.png)

将数据的信息整合进我们的似然函数：

$$
L(\mu | \vec{y}) \propto \exp\bigg[{-\frac{(5.735-\mu)^2}{2(0.5^2/25)}}\bigg] \;\;\;\; \text{ for } \; \mu \in (-\infty, \infty).
$$

```R
plot_normal_likelihood(y = concussion_subjects$volume, sigma = 0.5)+theme_bw()
```

![](https://picgo-wutao.oss-cn-shanghai.aliyuncs.com/image-20230719090825-sqhttax.png)

后验：

$$
\mu | \vec{y} \; \sim \; N\bigg(6.5\cdot\frac{0.5^2}{25\cdot0.4^2+0.5^2} + 5.735\cdot\frac{25\cdot 0.4^2}{25 \cdot 0.4^2+0.5^2}, \; \frac{0.4^2\cdot0.5^2}{25\cdot0.4^2+0.5^2}\bigg).
$$

$$
\mu | \vec{y} \; \sim \; N\bigg(5.78, 0.009^2 \bigg)
$$

后验均值中数据均值的权重大概是 94% 而先验的权重只有 6%；可以使用 `plot_normal_normal`​ 函数将三者展示在一个图上：

```R
plot_normal_normal(mean = 6.5, sd = 0.4, sigma = 0.5,
                   y_bar = 5.735, n = 25)+
theme_bw()
```

![](https://picgo-wutao.oss-cn-shanghai.aliyuncs.com/image-20230719091207-ue8do1e.png)

```R
summarize_normal_normal(mean = 6.5, sd = 0.4, sigma = 0.5,
                        y_bar = 5.735, n = 25)

      model mean mode      var      sd
1     prior 6.50 6.50 0.160000 0.40000
2 posterior 5.78 5.78 0.009412 0.09701
```

共轭家族模型的缺陷：

* 不够灵活，自由；比如正态模型总是单峰并且对称的
* 不总是能够得到一个均匀的先验
