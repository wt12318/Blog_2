

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=light>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/DNA.png">
  <link rel="icon" href="/img/DNA.png">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="Wu Tao">
  <meta name="keywords" content="">
  
    <meta name="description" content="循环神经网络及 Pytorch 实践">
<meta property="og:type" content="article">
<meta property="og:title" content="循环神经网络">
<meta property="og:url" content="http://example.com/2022/06/01/RNN/index.html">
<meta property="og:site_name" content="wutao&#39;s blog">
<meta property="og:description" content="循环神经网络及 Pytorch 实践">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://example.com/img/rnn.svg">
<meta property="article:published_time" content="2022-06-01T11:14:18.000Z">
<meta property="article:modified_time" content="2022-06-10T02:16:27.000Z">
<meta property="article:author" content="Wu Tao">
<meta property="article:tag" content="深度学习">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="http://example.com/img/rnn.svg">
  
  
  
  <title>循环神经网络 - wutao&#39;s blog</title>

  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.5.3/dist/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/github-markdown-css@4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="/lib/hint/hint.min.css" />

  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_kmeydafke9r.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  



  
<link rel="stylesheet" href="/css/custom.css">



  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"example.com","root":"/","version":"1.9.1","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"right","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"R","line_number":true,"lib":"highlightjs","highlightjs":{"style":"Stackoverflow Light","style_dark":"light"},"prismjs":{"style":"default","preprocess":true}},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":true,"follow_dnt":true,"baidu":null,"google":null,"gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":"A5lchRnum84Yumu5pVOSoVN8-MdYXbMMI","app_key":"runF3Mxw7648v64CISxiqMs8","server_url":null,"path":"window.location.pathname","ignore_local":false}},"search_path":"/local-search.xml"};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>

  
<meta name="generator" content="Hexo 5.4.2"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>wutao&#39;s blog</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                首页
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                归档
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                分类
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                标签
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                关于
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              &nbsp;<i class="iconfont icon-search"></i>&nbsp;
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">&nbsp;<i
                class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/default.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="循环神经网络"></span>
          
        </div>

        
          
  <div class="mt-3">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-author" aria-hidden="true"></i>
        Wu Tao
      </span>
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2022-06-01 19:14" pubdate>
          2022年6月1日 晚上
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          48k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          403 分钟
        
      </span>
    

    
    
      
        <span id="leancloud-page-views-container" class="post-meta" style="display: none">
          <i class="iconfont icon-eye" aria-hidden="true"></i>
          <span id="leancloud-page-views"></span> 次
        </span>
        
      
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">循环神经网络</h1>
            
            <div class="markdown-body">
              
              <p>循环神经网络及 Pytorch 实践</p>
<span id="more"></span>

<h2 id="循环神经网络"><a href="#循环神经网络" class="headerlink" title="循环神经网络"></a>循环神经网络</h2><p>对于表格数据和图像来说，我们都是假设数据是独立同分布的，当实际上数据并不都是如此的，比如文本中的单词，视频的帧，对话的声音信息，这些数据都是有序列特征的，也就是数据之间并不是独立的，因此我们需要一种特殊的模型去描述这类数据。</p>
<h3 id="序列模型"><a href="#序列模型" class="headerlink" title="序列模型"></a>序列模型</h3><p>例子：股票的预测，根据之前时间的股票价格来预测目前的股票价格：</p>
<p>$$<br>x_t  \sim P(x_t|x_{t-1},…, x_1)<br>$$</p>
<p>对类似上面的问题使用回归模型的难点在于：变量数量的变化，随着时间的推移我们需要纳入模型的变量数量会逐渐增多；解决这个问题有两个策略：</p>
<ul>
<li>自回归模型</li>
<li>马尔可夫模型</li>
</ul>
<h4 id="自回归模型"><a href="#自回归模型" class="headerlink" title="自回归模型"></a>自回归模型</h4><p>自回归模型指的是因变量和自变量的数据是一样的（从总体上来说）；自回归模型有两种：</p>
<ol>
<li><p>不考虑整个序列，而是一个固定大小 window 的序列，这样变量的数量就可以固定下来</p>
</li>
<li><p>将过去的观测整合成一个变量 $h_t$ 这样的模型也叫做隐自回归模型，因为这里的 ht 是一个隐变量</p>
<img src="https://picgo-wutao.oss-cn-shanghai.aliyuncs.com/img/image-20220411211540-nljbhay.png" srcset="/img/loading.gif" lazyload style="zoom:67%;" /></li>
</ol>
<p>隐变量实际是存在的，观测不到，潜变量可以是不存在的，人为设定的，比如聚类的类信息</p>
<p>因此整个序列出现的概率可以计算：</p>
<p>$$<br>P(x_1,…, x_t)&#x3D;\prod_{t&#x3D;1}^TP(x_t|x_{t-1},…x_1)<br>$$</p>
<h4 id="马尔可夫模型"><a href="#马尔可夫模型" class="headerlink" title="马尔可夫模型"></a>马尔可夫模型</h4><p>上面使用固定大小的 window 就可以说这个序列满足马尔可夫条件，如果这个 window 为 1， 那么就可以得到一阶马尔可夫模型:</p>
<p>$$<br>P(x_1,…, x_t)&#x3D;\prod_{t&#x3D;1}^TP(x_t|x_{t-1})<br>$$</p>
<h4 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h4><p>首先产生一些随机的数据，使用正弦函数加上一些噪音：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python">%matplotlib inline<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><span class="hljs-keyword">from</span> d2l <span class="hljs-keyword">import</span> torch <span class="hljs-keyword">as</span> d2l<br><br>T = <span class="hljs-number">1000</span>  <span class="hljs-comment"># Generate a total of 1000 points</span><br>time = torch.arange(<span class="hljs-number">1</span>, T + <span class="hljs-number">1</span>, dtype=torch.float32)<br>x = torch.sin(<span class="hljs-number">0.01</span> * time) + torch.normal(<span class="hljs-number">0</span>, <span class="hljs-number">0.2</span>, (T,))<br>d2l.plot(time, [x], <span class="hljs-string">&#x27;time&#x27;</span>, <span class="hljs-string">&#x27;x&#x27;</span>, xlim=[<span class="hljs-number">1</span>, <span class="hljs-number">1000</span>], figsize=(<span class="hljs-number">6</span>, <span class="hljs-number">3</span>))<br></code></pre></td></tr></table></figure>

<p>接下来就要生成训练数据：过去的窗口内的值作为 x ，当前的值作为 y；这里就会出现一个问题，开始的窗口长度的数值就没有足够的 x 输入，一般可以将这些数值扔掉或者 padding 为 0（这里直接丢弃）：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python">tau = <span class="hljs-number">4</span><br>features = torch.zeros((T - tau, tau))<span class="hljs-comment">##前4个不要</span><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(tau):<br>    features[:, i] = x[i: T - tau + i] <span class="hljs-comment">##</span><br>labels = x[tau:].reshape((-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>))<br><br>batch_size, n_train = <span class="hljs-number">16</span>, <span class="hljs-number">600</span><br><span class="hljs-comment"># Only the first `n_train` examples are used for training</span><br>train_iter = d2l.load_array((features[:n_train], labels[:n_train]),<br>                            batch_size, is_train=<span class="hljs-literal">True</span>)<br></code></pre></td></tr></table></figure>

<p>训练使用两层的 MLP 加上 ReLU 激活函数，loss 使用均方误差（MSEloss）（自回归）：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Function for initializing the weights of the network</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">init_weights</span>(<span class="hljs-params">m</span>):<br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">type</span>(m) == nn.Linear:<br>        nn.init.xavier_uniform_(m.weight)<br><br><span class="hljs-comment"># A simple MLP</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_net</span>():<br>    net = nn.Sequential(nn.Linear(<span class="hljs-number">4</span>, <span class="hljs-number">10</span>),<br>                        nn.ReLU(),<br>                        nn.Linear(<span class="hljs-number">10</span>, <span class="hljs-number">1</span>))<br>    net.apply(init_weights)<br>    <span class="hljs-keyword">return</span> net<br><br><span class="hljs-comment"># Note: `MSELoss` computes squared error without the 1/2 factor</span><br>loss = nn.MSELoss(reduction=<span class="hljs-string">&#x27;none&#x27;</span>)<br><br><span class="hljs-comment">##训练</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">train</span>(<span class="hljs-params">net, train_iter, loss, epochs, lr</span>):<br>    trainer = torch.optim.Adam(net.parameters(), lr)<br>    <span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(epochs):<br>        <span class="hljs-keyword">for</span> X, y <span class="hljs-keyword">in</span> train_iter:<br>            trainer.zero_grad()<br>            l = loss(net(X), y)<br>            l.<span class="hljs-built_in">sum</span>().backward()<br>            trainer.step()<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;epoch <span class="hljs-subst">&#123;epoch + <span class="hljs-number">1</span>&#125;</span>, &#x27;</span><br>              <span class="hljs-string">f&#x27;loss: <span class="hljs-subst">&#123;d2l.evaluate_loss(net, train_iter, loss):f&#125;</span>&#x27;</span>)<br><br>net = get_net()<br>train(net, train_iter, loss, <span class="hljs-number">5</span>, <span class="hljs-number">0.01</span>)<br></code></pre></td></tr></table></figure>

<p>进行预测：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">onestep_preds = net(features)<br>d2l.plot([time, time[tau:]], [x.detach().numpy(), onestep_preds.detach().numpy()], <span class="hljs-string">&#x27;time&#x27;</span>,<br>         <span class="hljs-string">&#x27;x&#x27;</span>, legend=[<span class="hljs-string">&#x27;data&#x27;</span>, <span class="hljs-string">&#x27;1-step preds&#x27;</span>], xlim=[<span class="hljs-number">1</span>, <span class="hljs-number">1000</span>], figsize=(<span class="hljs-number">6</span>, <span class="hljs-number">3</span>))<br></code></pre></td></tr></table></figure>

<img src="https://picgo-wutao.oss-cn-shanghai.aliyuncs.com/img/image-20220411223707-iy3hgos.png" srcset="/img/loading.gif" lazyload style="zoom:67%;" />



<p>这个只是前进一步的预测，如果我们要预测 604 个之后的就只能根据我们的预测来预测（因为上面训练的数据也就是观测的数据只到600），现在来看这些预测怎么样：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python">multistep_preds = torch.zeros(T)<br>multistep_preds[: n_train + tau] = x[: n_train + tau] <span class="hljs-comment">##只保留实际的604个值后面都是预测的</span><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n_train + tau, T):<br>    multistep_preds[i] = net(<br>        multistep_preds[i - tau:i].reshape((<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>)))<br><br>d2l.plot([time, time[tau:], time[n_train + tau:]],<br>         [x.detach().numpy(), onestep_preds.detach().numpy(),<br>          multistep_preds[n_train + tau:].detach().numpy()], <span class="hljs-string">&#x27;time&#x27;</span>,<br>         <span class="hljs-string">&#x27;x&#x27;</span>, legend=[<span class="hljs-string">&#x27;data&#x27;</span>, <span class="hljs-string">&#x27;1-step preds&#x27;</span>, <span class="hljs-string">&#x27;multistep preds&#x27;</span>],<br>         xlim=[<span class="hljs-number">1</span>, <span class="hljs-number">1000</span>], figsize=(<span class="hljs-number">6</span>, <span class="hljs-number">3</span>))<br></code></pre></td></tr></table></figure>

<img src="https://picgo-wutao.oss-cn-shanghai.aliyuncs.com/img/image-20220411224245-dlctp7g.png" srcset="/img/loading.gif" lazyload style="zoom:67%;" />



<p>可以看到在离 604 不久后预测就飞了，原因是误差的不断累积，比较不同窗口的区别：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python">max_steps = <span class="hljs-number">64</span><br><br>features = torch.zeros((T - tau - max_steps + <span class="hljs-number">1</span>, tau + max_steps))<br><span class="hljs-comment"># Column `i` (`i` &lt; `tau`) are observations from `x` for time steps from</span><br><span class="hljs-comment"># `i + 1` to `i + T - tau - max_steps + 1`</span><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(tau):<br>    features[:, i] = x[i: i + T - tau - max_steps + <span class="hljs-number">1</span>]<br><br><span class="hljs-comment"># Column `i` (`i` &gt;= `tau`) are the (`i - tau + 1`)-step-ahead predictions for</span><br><span class="hljs-comment"># time steps from `i + 1` to `i + T - tau - max_steps + 1`</span><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(tau, tau + max_steps):<br>    features[:, i] = net(features[:, i - tau:i]).reshape(-<span class="hljs-number">1</span>)<br><br>steps = (<span class="hljs-number">1</span>, <span class="hljs-number">4</span>, <span class="hljs-number">16</span>, <span class="hljs-number">64</span>)<br>d2l.plot([time[tau + i - <span class="hljs-number">1</span>: T - max_steps + i] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> steps],<br>         [features[:, (tau + i - <span class="hljs-number">1</span>)].detach().numpy() <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> steps], <span class="hljs-string">&#x27;time&#x27;</span>, <span class="hljs-string">&#x27;x&#x27;</span>,<br>         legend=[<span class="hljs-string">f&#x27;<span class="hljs-subst">&#123;i&#125;</span>-step preds&#x27;</span> <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> steps], xlim=[<span class="hljs-number">5</span>, <span class="hljs-number">1000</span>],<br>         figsize=(<span class="hljs-number">6</span>, <span class="hljs-number">3</span>))<br></code></pre></td></tr></table></figure>

<img src="https://picgo-wutao.oss-cn-shanghai.aliyuncs.com/img/image-20220411224545-130vwnu.png" srcset="/img/loading.gif" lazyload style="zoom:67%;" />

<h3 id="文本预处理"><a href="#文本预处理" class="headerlink" title="文本预处理"></a>文本预处理</h3><p>文本是最流行的序列数据的例子，文本预处理分为以下步骤：</p>
<ul>
<li>将文本以字符串读入内存</li>
<li>将字符串拆分成 token，可以是单个的词或者字符</li>
<li>构建一个词汇表，将 token 映射到数字索引</li>
<li>将文本转化成数字索引的序列</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> collections<br><span class="hljs-keyword">import</span> re<br><span class="hljs-keyword">from</span> d2l <span class="hljs-keyword">import</span> torch <span class="hljs-keyword">as</span> d2l<br></code></pre></td></tr></table></figure>

<h4 id="读入数据"><a href="#读入数据" class="headerlink" title="读入数据"></a>读入数据</h4><p>将文本读入成文本行构成的列表，每一行是一个字符串：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#@save</span><br>d2l.DATA_HUB[<span class="hljs-string">&#x27;time_machine&#x27;</span>] = (d2l.DATA_URL + <span class="hljs-string">&#x27;timemachine.txt&#x27;</span>,<br>                                <span class="hljs-string">&#x27;090b5e7e70c295757f55df93cb0a180b9691891a&#x27;</span>)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">read_time_machine</span>():  <span class="hljs-comment">#@save</span><br>    <span class="hljs-string">&quot;&quot;&quot;Load the time machine dataset into a list of text lines.&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(d2l.download(<span class="hljs-string">&#x27;time_machine&#x27;</span>), <span class="hljs-string">&#x27;r&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>        lines = f.readlines()<br>    <span class="hljs-keyword">return</span> [re.sub(<span class="hljs-string">&#x27;[^A-Za-z]+&#x27;</span>, <span class="hljs-string">&#x27; &#x27;</span>, line).strip().lower() <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> lines] <span class="hljs-comment">##非字母的字符去掉，并全部转化成小写</span><br><br>lines = read_time_machine()<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;# text lines: <span class="hljs-subst">&#123;<span class="hljs-built_in">len</span>(lines)&#125;</span>&#x27;</span>)<br><span class="hljs-built_in">print</span>(lines[<span class="hljs-number">0</span>])<br><span class="hljs-built_in">print</span>(lines[<span class="hljs-number">10</span>])<br><br>Downloading ../data/timemachine.txt <span class="hljs-keyword">from</span> http://d2l-data.s3-accelerate.amazonaws.com/timemachine.txt...<br><span class="hljs-comment"># text lines: 3221</span><br>the time machine by h g wells<br>twinkled <span class="hljs-keyword">and</span> his usually pale face was flushed <span class="hljs-keyword">and</span> animated the<br></code></pre></td></tr></table></figure>

<p>将字符串拆分成词或者字符，这个生成的 token 是一个 list of list，其中每个列表是构成一行的词：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">tokenize</span>(<span class="hljs-params">lines, token=<span class="hljs-string">&#x27;word&#x27;</span></span>):  <span class="hljs-comment">#@save</span><br>    <span class="hljs-string">&quot;&quot;&quot;Split text lines into word or character tokens.&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">if</span> token == <span class="hljs-string">&#x27;word&#x27;</span>:<br>        <span class="hljs-keyword">return</span> [line.split() <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> lines]<br>    <span class="hljs-keyword">elif</span> token == <span class="hljs-string">&#x27;char&#x27;</span>:<br>        <span class="hljs-keyword">return</span> [<span class="hljs-built_in">list</span>(line) <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> lines]<br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;ERROR: unknown token type: &#x27;</span> + token)<br><br>tokens = tokenize(lines)<br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">11</span>):<br>    <span class="hljs-built_in">print</span>(tokens[i])<br><br>[<span class="hljs-string">&#x27;the&#x27;</span>, <span class="hljs-string">&#x27;time&#x27;</span>, <span class="hljs-string">&#x27;machine&#x27;</span>, <span class="hljs-string">&#x27;by&#x27;</span>, <span class="hljs-string">&#x27;h&#x27;</span>, <span class="hljs-string">&#x27;g&#x27;</span>, <span class="hljs-string">&#x27;wells&#x27;</span>]<br>[]<br>[]<br>[]<br>[]<br>[<span class="hljs-string">&#x27;i&#x27;</span>]<br>[]<br>[]<br>[<span class="hljs-string">&#x27;the&#x27;</span>, <span class="hljs-string">&#x27;time&#x27;</span>, <span class="hljs-string">&#x27;traveller&#x27;</span>, <span class="hljs-string">&#x27;for&#x27;</span>, <span class="hljs-string">&#x27;so&#x27;</span>, <span class="hljs-string">&#x27;it&#x27;</span>, <span class="hljs-string">&#x27;will&#x27;</span>, <span class="hljs-string">&#x27;be&#x27;</span>, <span class="hljs-string">&#x27;convenient&#x27;</span>, <span class="hljs-string">&#x27;to&#x27;</span>, <span class="hljs-string">&#x27;speak&#x27;</span>, <span class="hljs-string">&#x27;of&#x27;</span>, <span class="hljs-string">&#x27;him&#x27;</span>]<br>[<span class="hljs-string">&#x27;was&#x27;</span>, <span class="hljs-string">&#x27;expounding&#x27;</span>, <span class="hljs-string">&#x27;a&#x27;</span>, <span class="hljs-string">&#x27;recondite&#x27;</span>, <span class="hljs-string">&#x27;matter&#x27;</span>, <span class="hljs-string">&#x27;to&#x27;</span>, <span class="hljs-string">&#x27;us&#x27;</span>, <span class="hljs-string">&#x27;his&#x27;</span>, <span class="hljs-string">&#x27;grey&#x27;</span>, <span class="hljs-string">&#x27;eyes&#x27;</span>, <span class="hljs-string">&#x27;shone&#x27;</span>, <span class="hljs-string">&#x27;and&#x27;</span>]<br>[<span class="hljs-string">&#x27;twinkled&#x27;</span>, <span class="hljs-string">&#x27;and&#x27;</span>, <span class="hljs-string">&#x27;his&#x27;</span>, <span class="hljs-string">&#x27;usually&#x27;</span>, <span class="hljs-string">&#x27;pale&#x27;</span>, <span class="hljs-string">&#x27;face&#x27;</span>, <span class="hljs-string">&#x27;was&#x27;</span>, <span class="hljs-string">&#x27;flushed&#x27;</span>, <span class="hljs-string">&#x27;and&#x27;</span>, <span class="hljs-string">&#x27;animated&#x27;</span>, <span class="hljs-string">&#x27;the&#x27;</span>]<br></code></pre></td></tr></table></figure>

<p>接下来就要创建一个词汇表将 token 映射到数字索引：先计算文本中唯一 token 的频率表，叫做语料（corpus），然后根据其频率赋予索引（从大到小，从0开始），有些出现较少的 token 可以去掉以减少复杂性，另外还可以添加一些特殊的token，比如在语料中不存在或者被移除的 token 可以用<code> &lt;unk&gt;</code> 来表示，开始的token 用 <code>&lt;bos&gt;</code>，结束的 token 用 <code>&lt;eos&gt;</code> 表示，padding 可以使用 <code>&lt;pad&gt;</code> 表示等：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">count_corpus</span>(<span class="hljs-params">tokens</span>):  <span class="hljs-comment">#@save</span><br>    <span class="hljs-string">&quot;&quot;&quot;Count token frequencies.&quot;&quot;&quot;</span><br>    <span class="hljs-comment"># Here `tokens` is a 1D list or 2D list</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(tokens) == <span class="hljs-number">0</span> <span class="hljs-keyword">or</span> <span class="hljs-built_in">isinstance</span>(tokens[<span class="hljs-number">0</span>], <span class="hljs-built_in">list</span>):<br>        <span class="hljs-comment"># Flatten a list of token lists into a list of tokens</span><br>        tokens = [token <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> tokens <span class="hljs-keyword">for</span> token <span class="hljs-keyword">in</span> line]<br>    <span class="hljs-keyword">return</span> collections.Counter(tokens)<br></code></pre></td></tr></table></figure>

<p>注意这里的一个 flatten 二维列表的技巧 <code>[token for line in tokens for token in line]</code>，先运行 <code>line in tokens</code> 每次拿出一个列表，然后运行 <code>token in line</code> 每次拿出该列表中的一个词作为最开始的 <code>token</code>：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">a = [[<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>],[<span class="hljs-number">4</span>,<span class="hljs-number">5</span>,<span class="hljs-number">6</span>]]<br>[i <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> a <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> j ]<br><br>[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>, <span class="hljs-number">6</span>]<br></code></pre></td></tr></table></figure>

<p>创建词汇表：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Vocab</span>:  <span class="hljs-comment">#@save</span><br>    <span class="hljs-string">&quot;&quot;&quot;Vocabulary for text.&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, tokens=<span class="hljs-literal">None</span>, min_freq=<span class="hljs-number">0</span>, reserved_tokens=<span class="hljs-literal">None</span></span>):<br>        <span class="hljs-keyword">if</span> tokens <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:<br>            tokens = []<br>        <span class="hljs-keyword">if</span> reserved_tokens <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:<br>            reserved_tokens = []<br>        <span class="hljs-comment"># Sort according to frequencies</span><br>        counter = count_corpus(tokens)<br>        self._token_freqs = <span class="hljs-built_in">sorted</span>(counter.items(), key=<span class="hljs-keyword">lambda</span> x: x[<span class="hljs-number">1</span>],<br>                                   reverse=<span class="hljs-literal">True</span>)<span class="hljs-comment">##按照 key进行排序，key选择的是字典中的值，也就是频率</span><br>        <span class="hljs-comment"># The index for the unknown token is 0</span><br>        self.idx_to_token = [<span class="hljs-string">&#x27;&lt;unk&gt;&#x27;</span>] + reserved_tokens<br>        self.token_to_idx = &#123;token: idx<br>                             <span class="hljs-keyword">for</span> idx, token <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(self.idx_to_token)&#125;<span class="hljs-comment">##enumerate返回的一个元素是从零开始的索引</span><br>        <span class="hljs-keyword">for</span> token, freq <span class="hljs-keyword">in</span> self._token_freqs:<br>            <span class="hljs-keyword">if</span> freq &lt; min_freq:<br>                <span class="hljs-keyword">break</span><br>            <span class="hljs-keyword">if</span> token <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> self.token_to_idx:<br>                self.idx_to_token.append(token)<br>                self.token_to_idx[token] = <span class="hljs-built_in">len</span>(self.idx_to_token) - <span class="hljs-number">1</span><span class="hljs-comment">##逐渐增加index</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__len__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">len</span>(self.idx_to_token)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__getitem__</span>(<span class="hljs-params">self, tokens</span>):<br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> <span class="hljs-built_in">isinstance</span>(tokens, (<span class="hljs-built_in">list</span>, <span class="hljs-built_in">tuple</span>)):<br>            <span class="hljs-keyword">return</span> self.token_to_idx.get(tokens, self.unk)<span class="hljs-comment">##dict.get(key,value)当key 不存在时返回 value，这里就是对 unkown 的 token 返回 0</span><br>        <span class="hljs-keyword">return</span> [self.__getitem__(token) <span class="hljs-keyword">for</span> token <span class="hljs-keyword">in</span> tokens]<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">to_tokens</span>(<span class="hljs-params">self, indices</span>):<br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> <span class="hljs-built_in">isinstance</span>(indices, (<span class="hljs-built_in">list</span>, <span class="hljs-built_in">tuple</span>)):<br>            <span class="hljs-keyword">return</span> self.idx_to_token[indices]<br>        <span class="hljs-keyword">return</span> [self.idx_to_token[index] <span class="hljs-keyword">for</span> index <span class="hljs-keyword">in</span> indices]<br><br><span class="hljs-meta">    @property</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">unk</span>(<span class="hljs-params">self</span>):  <span class="hljs-comment"># Index for the unknown token</span><br>        <span class="hljs-keyword">return</span> <span class="hljs-number">0</span><br><br><span class="hljs-meta">    @property</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">token_freqs</span>(<span class="hljs-params">self</span>):  <span class="hljs-comment"># Index for the unknown token</span><br>        <span class="hljs-keyword">return</span> self._token_freqs<br></code></pre></td></tr></table></figure>

<p>接下来我们就可以用上面的类及函数将time machine 这个文本转化为数字：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">load_corpus_time_machine</span>(<span class="hljs-params">max_tokens=-<span class="hljs-number">1</span></span>):  <span class="hljs-comment">#@save</span><br>    <span class="hljs-string">&quot;&quot;&quot;Return token indices and the vocabulary of the time machine dataset.&quot;&quot;&quot;</span><br>    lines = read_time_machine()<br>    tokens = tokenize(lines, <span class="hljs-string">&#x27;char&#x27;</span>)<span class="hljs-comment">##以字符而不是词</span><br>    vocab = Vocab(tokens)<br>    <span class="hljs-comment"># Since each text line in the time machine dataset is not necessarily a</span><br>    <span class="hljs-comment"># sentence or a paragraph, flatten all the text lines into a single list</span><br>    corpus = [vocab[token] <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> tokens <span class="hljs-keyword">for</span> token <span class="hljs-keyword">in</span> line]<span class="hljs-comment">##返回每个字的index</span><br>    <span class="hljs-keyword">if</span> max_tokens &gt; <span class="hljs-number">0</span>:<br>        corpus = corpus[:max_tokens]<br>    <span class="hljs-keyword">return</span> corpus, vocab<br><br>corpus, vocab = load_corpus_time_machine()<br><span class="hljs-built_in">len</span>(corpus), <span class="hljs-built_in">len</span>(vocab)<br><br>(<span class="hljs-number">170580</span>, <span class="hljs-number">28</span>)<br></code></pre></td></tr></table></figure>

<h3 id="语言模型和数据集"><a href="#语言模型和数据集" class="headerlink" title="语言模型和数据集"></a>语言模型和数据集</h3><p>上面我们将文本序列转化成 token，因此一个长度为 T 的文本序列可以表示成一个 token 的序列：$x_1,x_2,…,x_T$ 语言模型的目的就是估计联合概率：</p>
<p>$$<br>P(x_1,x_2,…,x_T)<br>$$</p>
<p>由基本的条件概率我们可以得到：</p>
<p>$$<br>P(x_1, x_2, \ldots, x_T) &#x3D; \prod_{t&#x3D;1}^T P(x_t  \mid  x_1, \ldots, x_{t-1}).<br>$$</p>
<p>因此要计算这个语言模型，我们需要计算词的概率和给定前面的词的条件概率，对于一些大型的文本可以使用词的频率来估计这种概率，但是这有一个问题：对于一些词的组合，可能出现的次数比较少（越比如对于固定的有3个词的词组，可能就不会出现几次），对于这个问题通常的策略是 <em>Laplace smoothing</em>，也就是加上一个小的常数：</p>
<p>$$<br>\hat{P}(x)  &#x3D; \frac{n(x) + \epsilon_1&#x2F;m}{n + \epsilon_1}<br>$$</p>
<p>$$<br>\hat{P}(x’ \mid x) &#x3D; \frac{n(x, x’) + \epsilon_2 \hat{P}(x’)}{n(x) + \epsilon_2}<br>$$</p>
<p>$$<br>\hat{P}(x’’ \mid x,x’)  &#x3D; \frac{n(x, x’,x’’) + \epsilon_3 \hat{P}(x’’)}{n(x, x’) + \epsilon_3}<br>$$</p>
<p>但是这样近似还是会存在一些问题：</p>
<ul>
<li>需要存储所有的词，词组的 counts</li>
<li>这个方法忽略了词的意思</li>
<li>对于一些长的词序列，在整个文本中可能一次都没有，那么这种方法也是不行的</li>
</ul>
<p>我们还可以将前面讲过的马尔可夫假设引进语言模型，可以得到不同 gram 的模型估计（对应着一阶，二阶，三阶马尔可夫假设）：</p>
<p>$$<br>P(x_1, x_2, x_3, x_4) &#x3D;  P(x_1) P(x_2) P(x_3) P(x_4)<br>$$</p>
<p>$$<br>P(x_1, x_2, x_3, x_4) &#x3D;  P(x_1) P(x_2  \mid  x_1) P(x_3  \mid  x_2) P(x_4  \mid  x_3)<br>$$</p>
<p>$$<br>P(x_1, x_2, x_3, x_4) &#x3D;  P(x_1) P(x_2  \mid  x_1) P(x_3  \mid  x_1, x_2) P(x_4  \mid  x_2, x_3)<br>$$</p>
<h4 id="读取长序列数据"><a href="#读取长序列数据" class="headerlink" title="读取长序列数据"></a>读取长序列数据</h4><p>对于一些很长的序列，模型不能一次性处理，我们需要将这些长序列分割成短序列；首先假设使用神经网络来训练语言模型，神经网络处理的是小批量的序列输入，这些序列有着预定的长度，接下来的问题就是<strong>如何从长的序列中随机地读取小批量的特征和标签</strong>。</p>
<p>如果短序列长度是5，那么可以有如下的选择：</p>
<img src="https://picgo-wutao.oss-cn-shanghai.aliyuncs.com/img/image-20220414105111-jube13u.png" srcset="/img/loading.gif" lazyload style="zoom:67%;" />



<p>对于开始的 offset 我们一般是随机的选择 offset 的大小，从而使得所有可能的子序列的覆盖度比较大，并且增加随机性；选择子序列的方法有两种：随机抽样和顺序分割，随机抽样中两个相邻的 minibatch 在原始序列中不一定相邻，而顺序分割则是相邻的。</p>
<h5 id="随机抽样"><a href="#随机抽样" class="headerlink" title="随机抽样"></a>随机抽样</h5><p>在序列模型中，目标是基于我们看过的 token 预测下一个token，因此标签为原始的序列向后移动一个 token（比如说上面第一个子序列为 the t 其标签为 he ti）:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">seq_data_iter_random</span>(<span class="hljs-params">corpus, batch_size, num_steps</span>):  <span class="hljs-comment">#@save</span><br>    <span class="hljs-string">&quot;&quot;&quot;Generate a minibatch of subsequences using random sampling.&quot;&quot;&quot;</span><br>    <span class="hljs-comment"># Start with a random offset (inclusive of `num_steps - 1`) to partition a</span><br>    <span class="hljs-comment"># sequence</span><br>    corpus = corpus[random.randint(<span class="hljs-number">0</span>, num_steps - <span class="hljs-number">1</span>):]<br>    <span class="hljs-comment"># Subtract 1 since we need to account for labels</span><br>    num_subseqs = (<span class="hljs-built_in">len</span>(corpus) - <span class="hljs-number">1</span>) // num_steps<br>    <span class="hljs-comment"># The starting indices for subsequences of length `num_steps`</span><br>    initial_indices = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, num_subseqs * num_steps, num_steps))<br>    <span class="hljs-comment"># In random sampling, the subsequences from two adjacent random</span><br>    <span class="hljs-comment"># minibatches during iteration are not necessarily adjacent on the</span><br>    <span class="hljs-comment"># original sequence</span><br>    random.shuffle(initial_indices)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">data</span>(<span class="hljs-params">pos</span>):<br>        <span class="hljs-comment"># Return a sequence of length `num_steps` starting from `pos`</span><br>        <span class="hljs-keyword">return</span> corpus[pos: pos + num_steps]<br><br>    num_batches = num_subseqs // batch_size<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, batch_size * num_batches, batch_size):<br>        <span class="hljs-comment"># Here, `initial_indices` contains randomized starting indices for</span><br>        <span class="hljs-comment"># subsequences</span><br>        initial_indices_per_batch = initial_indices[i: i + batch_size]<br>        X = [data(j) <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> initial_indices_per_batch]<br>        Y = [data(j + <span class="hljs-number">1</span>) <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> initial_indices_per_batch]<br>        <span class="hljs-keyword">yield</span> torch.tensor(X), torch.tensor(Y)<br></code></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python">my_seq = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">range</span>(<span class="hljs-number">35</span>))<br><span class="hljs-keyword">for</span> X, Y <span class="hljs-keyword">in</span> seq_data_iter_random(my_seq, batch_size=<span class="hljs-number">2</span>, num_steps=<span class="hljs-number">5</span>):<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;X: &#x27;</span>, X, <span class="hljs-string">&#x27;\nY:&#x27;</span>, Y)<br><br>X:  tensor([[<span class="hljs-number">10</span>, <span class="hljs-number">11</span>, <span class="hljs-number">12</span>, <span class="hljs-number">13</span>, <span class="hljs-number">14</span>],<br>        [<span class="hljs-number">15</span>, <span class="hljs-number">16</span>, <span class="hljs-number">17</span>, <span class="hljs-number">18</span>, <span class="hljs-number">19</span>]]) <br>Y: tensor([[<span class="hljs-number">11</span>, <span class="hljs-number">12</span>, <span class="hljs-number">13</span>, <span class="hljs-number">14</span>, <span class="hljs-number">15</span>],<br>        [<span class="hljs-number">16</span>, <span class="hljs-number">17</span>, <span class="hljs-number">18</span>, <span class="hljs-number">19</span>, <span class="hljs-number">20</span>]])<br>X:  tensor([[<span class="hljs-number">20</span>, <span class="hljs-number">21</span>, <span class="hljs-number">22</span>, <span class="hljs-number">23</span>, <span class="hljs-number">24</span>],<br>        [ <span class="hljs-number">5</span>,  <span class="hljs-number">6</span>,  <span class="hljs-number">7</span>,  <span class="hljs-number">8</span>,  <span class="hljs-number">9</span>]]) <br>Y: tensor([[<span class="hljs-number">21</span>, <span class="hljs-number">22</span>, <span class="hljs-number">23</span>, <span class="hljs-number">24</span>, <span class="hljs-number">25</span>],<br>        [ <span class="hljs-number">6</span>,  <span class="hljs-number">7</span>,  <span class="hljs-number">8</span>,  <span class="hljs-number">9</span>, <span class="hljs-number">10</span>]])<br>X:  tensor([[<span class="hljs-number">25</span>, <span class="hljs-number">26</span>, <span class="hljs-number">27</span>, <span class="hljs-number">28</span>, <span class="hljs-number">29</span>],<br>        [ <span class="hljs-number">0</span>,  <span class="hljs-number">1</span>,  <span class="hljs-number">2</span>,  <span class="hljs-number">3</span>,  <span class="hljs-number">4</span>]]) <br>Y: tensor([[<span class="hljs-number">26</span>, <span class="hljs-number">27</span>, <span class="hljs-number">28</span>, <span class="hljs-number">29</span>, <span class="hljs-number">30</span>],<br>        [ <span class="hljs-number">1</span>,  <span class="hljs-number">2</span>,  <span class="hljs-number">3</span>,  <span class="hljs-number">4</span>,  <span class="hljs-number">5</span>]])<br></code></pre></td></tr></table></figure>

<h5 id="顺序分割"><a href="#顺序分割" class="headerlink" title="顺序分割"></a>顺序分割</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">seq_data_iter_sequential</span>(<span class="hljs-params">corpus, batch_size, num_steps</span>):  <span class="hljs-comment">#@save</span><br>    <span class="hljs-string">&quot;&quot;&quot;Generate a minibatch of subsequences using sequential partitioning.&quot;&quot;&quot;</span><br>    <span class="hljs-comment"># Start with a random offset to partition a sequence</span><br>    offset = random.randint(<span class="hljs-number">0</span>, num_steps)<br>    num_tokens = ((<span class="hljs-built_in">len</span>(corpus) - offset - <span class="hljs-number">1</span>) // batch_size) * batch_size<br>    Xs = torch.tensor(corpus[offset: offset + num_tokens])<br>    Ys = torch.tensor(corpus[offset + <span class="hljs-number">1</span>: offset + <span class="hljs-number">1</span> + num_tokens])<br>    Xs, Ys = Xs.reshape(batch_size, -<span class="hljs-number">1</span>), Ys.reshape(batch_size, -<span class="hljs-number">1</span>)<br>    num_batches = Xs.shape[<span class="hljs-number">1</span>] // num_steps<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, num_steps * num_batches, num_steps):<br>        X = Xs[:, i: i + num_steps]<br>        Y = Ys[:, i: i + num_steps]<br>        <span class="hljs-keyword">yield</span> X, Y<br></code></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">for</span> X, Y <span class="hljs-keyword">in</span> seq_data_iter_sequential(my_seq, batch_size=<span class="hljs-number">2</span>, num_steps=<span class="hljs-number">5</span>):<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;X: &#x27;</span>, X, <span class="hljs-string">&#x27;\nY:&#x27;</span>, Y)<br><br>X:  tensor([[ <span class="hljs-number">4</span>,  <span class="hljs-number">5</span>,  <span class="hljs-number">6</span>,  <span class="hljs-number">7</span>,  <span class="hljs-number">8</span>],<br>        [<span class="hljs-number">19</span>, <span class="hljs-number">20</span>, <span class="hljs-number">21</span>, <span class="hljs-number">22</span>, <span class="hljs-number">23</span>]]) <br>Y: tensor([[ <span class="hljs-number">5</span>,  <span class="hljs-number">6</span>,  <span class="hljs-number">7</span>,  <span class="hljs-number">8</span>,  <span class="hljs-number">9</span>],<br>        [<span class="hljs-number">20</span>, <span class="hljs-number">21</span>, <span class="hljs-number">22</span>, <span class="hljs-number">23</span>, <span class="hljs-number">24</span>]])<br>X:  tensor([[ <span class="hljs-number">9</span>, <span class="hljs-number">10</span>, <span class="hljs-number">11</span>, <span class="hljs-number">12</span>, <span class="hljs-number">13</span>],<br>        [<span class="hljs-number">24</span>, <span class="hljs-number">25</span>, <span class="hljs-number">26</span>, <span class="hljs-number">27</span>, <span class="hljs-number">28</span>]]) <br>Y: tensor([[<span class="hljs-number">10</span>, <span class="hljs-number">11</span>, <span class="hljs-number">12</span>, <span class="hljs-number">13</span>, <span class="hljs-number">14</span>],<br>        [<span class="hljs-number">25</span>, <span class="hljs-number">26</span>, <span class="hljs-number">27</span>, <span class="hljs-number">28</span>, <span class="hljs-number">29</span>]])<br>X:  tensor([[<span class="hljs-number">14</span>, <span class="hljs-number">15</span>, <span class="hljs-number">16</span>, <span class="hljs-number">17</span>, <span class="hljs-number">18</span>],<br>        [<span class="hljs-number">29</span>, <span class="hljs-number">30</span>, <span class="hljs-number">31</span>, <span class="hljs-number">32</span>, <span class="hljs-number">33</span>]]) <br>Y: tensor([[<span class="hljs-number">15</span>, <span class="hljs-number">16</span>, <span class="hljs-number">17</span>, <span class="hljs-number">18</span>, <span class="hljs-number">19</span>],<br>        [<span class="hljs-number">30</span>, <span class="hljs-number">31</span>, <span class="hljs-number">32</span>, <span class="hljs-number">33</span>, <span class="hljs-number">34</span>]])<br></code></pre></td></tr></table></figure>

<p>将上面的函数包装：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">SeqDataLoader</span>:  <span class="hljs-comment">#@save</span><br>    <span class="hljs-string">&quot;&quot;&quot;An iterator to load sequence data.&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, batch_size, num_steps, use_random_iter, max_tokens</span>):<br>        <span class="hljs-keyword">if</span> use_random_iter:<br>            self.data_iter_fn = d2l.seq_data_iter_random<br>        <span class="hljs-keyword">else</span>:<br>            self.data_iter_fn = d2l.seq_data_iter_sequential<br>        self.corpus, self.vocab = d2l.load_corpus_time_machine(max_tokens)<br>        self.batch_size, self.num_steps = batch_size, num_steps<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__iter__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> self.data_iter_fn(self.corpus, self.batch_size, self.num_steps)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">load_data_time_machine</span>(<span class="hljs-params">batch_size, num_steps,  <span class="hljs-comment">#@save</span></span><br><span class="hljs-params">                           use_random_iter=<span class="hljs-literal">False</span>, max_tokens=<span class="hljs-number">10000</span></span>):<br>    <span class="hljs-string">&quot;&quot;&quot;Return the iterator and the vocabulary of the time machine dataset.&quot;&quot;&quot;</span><br>    data_iter = SeqDataLoader(<br>        batch_size, num_steps, use_random_iter, max_tokens)<br>    <span class="hljs-keyword">return</span> data_iter, data_iter.vocab<br></code></pre></td></tr></table></figure>

<h3 id="循环神经网络-1"><a href="#循环神经网络-1" class="headerlink" title="循环神经网络"></a>循环神经网络</h3><p>之前讲过为了避免随着预测步长的增加，模型的变量越来越多，我们可以使用一个隐变量模型：</p>
<p>$$<br>P(x_t \mid x_{t-1}, \ldots, x_1) \approx P(x_t \mid h_{t-1}),<br>$$</p>
<p>$h_{t-1}$ 是隐状态或者叫隐变量，保留了在 t-1 步及之前的信息，在t步的隐变量由t步的输入和前一步的隐变量计算得到：</p>
<p>$$<br>h_t &#x3D; f(x_{t}, h_{t-1}).<br>$$</p>
<p>这个 f 可以由神经网络来估计：</p>
<p>$$<br>H_t &#x3D; \phi(X_t W_{xh} + H_{t-1} W_{hh}  + b_h).<br>$$</p>
<p>在每个时间步，可以根据 Ht 得到该时间步的输出：</p>
<p>$$<br>O_t &#x3D; H_t W_{hq} +b_q.<br>$$</p>
<p>因此一个 RNN 的结构为：</p>
<img src="https://picgo-wutao.oss-cn-shanghai.aliyuncs.com/img/Whiteboard-20220417113658-2bzy5b5.png" srcset="/img/loading.gif" lazyload style="zoom:50%;" />



<p>下面以一个单词分割成字符预测为例：</p>
<img src="https://picgo-wutao.oss-cn-shanghai.aliyuncs.com/img/image-20220417114034-k39nglx.png" srcset="/img/loading.gif" lazyload style="zoom:50%;" />



<p>在预测中使用类似交叉熵误差的loss，叫做 <em>perplexity</em> （困惑度）：<br>$$<br>\exp\left(-\frac{1}{n} \sum_{t&#x3D;1}^n \log P(x_t \mid x_{t-1}, \ldots, x_1)\right).<br>$$</p>
<p>在每一个时间步的输出就是每个 token 的概率分布</p>
<h3 id="循环神经网络的实现"><a href="#循环神经网络的实现" class="headerlink" title="循环神经网络的实现"></a>循环神经网络的实现</h3><p>首先读入数据：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python">%matplotlib inline<br><span class="hljs-keyword">import</span> math<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><span class="hljs-keyword">from</span> torch.nn <span class="hljs-keyword">import</span> functional <span class="hljs-keyword">as</span> F<br><span class="hljs-keyword">from</span> d2l <span class="hljs-keyword">import</span> torch <span class="hljs-keyword">as</span> d2l<br><br>batch_size, num_steps = <span class="hljs-number">32</span>, <span class="hljs-number">35</span><br>train_iter, vocab = d2l.load_data_time_machine(batch_size, num_steps)<br></code></pre></td></tr></table></figure>

<p>由于每个token 是一个数值的index，我们需要将其转换为 one-hot 编码，ont-hot 向量的长度为所有token 的数量，某个token 的 one-hot向量就是在相应的token index数值位置是1 其余都是0，如：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python">F.one_hot(torch.tensor([<span class="hljs-number">0</span>, <span class="hljs-number">2</span>]), <span class="hljs-built_in">len</span>(vocab))<br><br>tensor([[<span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>,<br>         <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>],<br>        [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>,<br>         <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>]])<br></code></pre></td></tr></table></figure>

<p>还需要注意的一点是我们每次抽样得到的mini-batch 的大小为 （批量大小*时间步），比如下面数据的批量大小是2，时间步是5：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">X = torch.arange(<span class="hljs-number">10</span>).reshape((<span class="hljs-number">2</span>, <span class="hljs-number">5</span>))<br>X<br><br>tensor([[<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>],<br>        [<span class="hljs-number">5</span>, <span class="hljs-number">6</span>, <span class="hljs-number">7</span>, <span class="hljs-number">8</span>, <span class="hljs-number">9</span>]])<br></code></pre></td></tr></table></figure>

<p>在进行one-hot转换后我们需要将其转换为 （时间步*批量大小*token数量），这样方便进行时间步的取样：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><code class="hljs python">X.T<br><br>tensor([[<span class="hljs-number">0</span>, <span class="hljs-number">5</span>],<br>        [<span class="hljs-number">1</span>, <span class="hljs-number">6</span>],<br>        [<span class="hljs-number">2</span>, <span class="hljs-number">7</span>],<br>        [<span class="hljs-number">3</span>, <span class="hljs-number">8</span>],<br>        [<span class="hljs-number">4</span>, <span class="hljs-number">9</span>]])<br><br>F.one_hot(X.T,<span class="hljs-built_in">len</span>(vocab))<br>tensor([[[<span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>,<br>          <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>],<br>         [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>,<br>          <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>]],<br><br>        [[<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>,<br>          <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>],<br>         [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>,<br>          <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>]],<br><br>        [[<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>,<br>          <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>],<br>         [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>,<br>          <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>]],<br><br>        [[<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>,<br>          <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>],<br>         [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>,<br>          <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>]],<br><br>        [[<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>,<br>          <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>],<br>         [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>,<br>          <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>]]])<br><br>F.one_hot(X.T, <span class="hljs-number">28</span>).shape<br>torch.Size([<span class="hljs-number">5</span>, <span class="hljs-number">2</span>, <span class="hljs-number">28</span>])<br></code></pre></td></tr></table></figure>

<p>接下来我们需要初始化模型的参数（也就是上面讲过的 3 个 W 和两个 b）：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_params</span>(<span class="hljs-params">vocab_size, num_hiddens, device</span>):<br>    num_inputs = num_outputs = vocab_size<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">normal</span>(<span class="hljs-params">shape</span>):<br>        <span class="hljs-keyword">return</span> torch.randn(size=shape, device=device) * <span class="hljs-number">0.01</span><span class="hljs-comment">##为什么0.01</span><br><br>    <span class="hljs-comment"># Hidden layer parameters</span><br>    W_xh = normal((num_inputs, num_hiddens))<br>    W_hh = normal((num_hiddens, num_hiddens))<br>    b_h = torch.zeros(num_hiddens, device=device)<br>    <span class="hljs-comment"># Output layer parameters</span><br>    W_hq = normal((num_hiddens, num_outputs))<br>    b_q = torch.zeros(num_outputs, device=device)<br>    <span class="hljs-comment"># Attach gradients</span><br>    params = [W_xh, W_hh, b_h, W_hq, b_q]<br>    <span class="hljs-keyword">for</span> param <span class="hljs-keyword">in</span> params:<br>        param.requires_grad_(<span class="hljs-literal">True</span>)<br>    <span class="hljs-keyword">return</span> params<br></code></pre></td></tr></table></figure>

<p>在 RNN 模型中第一个时间步是没有上一个隐状态传过来的，因此需要初始化一个状态，这里使用全0来初始化：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">init_rnn_state</span>(<span class="hljs-params">batch_size, num_hiddens, device</span>):<br>    <span class="hljs-keyword">return</span> (torch.zeros((batch_size, num_hiddens), device=device), )<br></code></pre></td></tr></table></figure>

<p>下面的 rnn 函数定义了在每个时间步如何计算隐状态和输出，注意前面我们将批量的输入进行了转置，使得最外面的维度表示时间步，因此下面是对每个时间步的批量进行迭代运算：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">rnn</span>(<span class="hljs-params">inputs, state, params</span>):<br>    <span class="hljs-comment"># Here `inputs` shape: (`num_steps`, `batch_size`, `vocab_size`)</span><br>    W_xh, W_hh, b_h, W_hq, b_q = params<br>    H, = state<br>    outputs = []<br>    <span class="hljs-comment"># Shape of `X`: (`batch_size`, `vocab_size`)</span><br>    <span class="hljs-keyword">for</span> X <span class="hljs-keyword">in</span> inputs:<br>        H = torch.tanh(torch.mm(X, W_xh) + torch.mm(H, W_hh) + b_h)<span class="hljs-comment">##基于上一个 H 和这一步的 X 来更新这一步的 H</span><br>        Y = torch.mm(H, W_hq) + b_q <span class="hljs-comment">##基于这一步的 H来预测下一步的Y</span><br>        outputs.append(Y)<br>    <span class="hljs-keyword">return</span> torch.cat(outputs, dim=<span class="hljs-number">0</span>), (H,)<br></code></pre></td></tr></table></figure>

<p>注意最后一句输出将 output 在第 0 个维度上拼起来了：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">torch.cat(outputs, dim=<span class="hljs-number">0</span>).shape<br><span class="hljs-comment">#torch.Size([10, 28])</span><br></code></pre></td></tr></table></figure>

<p>其实 RNN 的每个批量的输出和多分类问题是一样的，也就是说虽然批量是 2，但是有 5 个时间步，因此也就相当于有 10 个 “样本”，每个样本的输出都是词汇表长度的向量（28），也就是进行28 类的预测。</p>
<p>现在所有的函数都有了，我们可以定义一个 RNN 模型将这些函数包装到一起：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">RNNModelScratch</span>: <span class="hljs-comment">#@save</span><br>    <span class="hljs-string">&quot;&quot;&quot;A RNN Model implemented from scratch.&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, vocab_size, num_hiddens, device,</span><br><span class="hljs-params">                 get_params, init_state, forward_fn</span>):<br>        self.vocab_size, self.num_hiddens = vocab_size, num_hiddens<br>        self.params = get_params(vocab_size, num_hiddens, device)<br>        self.init_state, self.forward_fn = init_state, forward_fn<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__call__</span>(<span class="hljs-params">self, X, state</span>):<br>        X = F.one_hot(X.T, self.vocab_size).<span class="hljs-built_in">type</span>(torch.float32)<br>        <span class="hljs-keyword">return</span> self.forward_fn(X, state, self.params)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">begin_state</span>(<span class="hljs-params">self, batch_size, device</span>):<br>        <span class="hljs-keyword">return</span> self.init_state(batch_size, self.num_hiddens, device)<br></code></pre></td></tr></table></figure>

<p>测试一下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python">num_hiddens = <span class="hljs-number">512</span><br>net = RNNModelScratch(<span class="hljs-built_in">len</span>(vocab), num_hiddens, d2l.try_gpu(), get_params,<br>                      init_rnn_state, rnn)<br>state = net.begin_state(X.shape[<span class="hljs-number">0</span>], d2l.try_gpu())<br>Y, new_state = net(X.to(d2l.try_gpu()), state)<br>Y.shape, <span class="hljs-built_in">len</span>(new_state), new_state[<span class="hljs-number">0</span>].shape<br><span class="hljs-comment">#(torch.Size([10, 28]), 1, torch.Size([2, 512]))</span><br></code></pre></td></tr></table></figure>

<h4 id="预测"><a href="#预测" class="headerlink" title="预测"></a>预测</h4><p>在训练模型之前先来看看这么用这个 RNN 模型进行预测，预测分为两步：</p>
<ul>
<li>warm-up：根据用户提供的起始字符（<strong>prefix</strong>）来计算这些字符的隐状态，但是不需要输出（因为已经提供输出了）</li>
<li>预测：基于上一步计算的隐状态继续后面的隐状态和输出的生成</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">predict_ch8</span>(<span class="hljs-params">prefix, num_preds, net, vocab, device</span>):  <span class="hljs-comment">#@save</span><br>    <span class="hljs-string">&quot;&quot;&quot;Generate new characters following the `prefix`.&quot;&quot;&quot;</span><br>    state = net.begin_state(batch_size=<span class="hljs-number">1</span>, device=device)<br>    outputs = [vocab[prefix[<span class="hljs-number">0</span>]]] <span class="hljs-comment">##第一个output就是提供的字符的第一个</span><br>    get_input = <span class="hljs-keyword">lambda</span>: torch.tensor([outputs[-<span class="hljs-number">1</span>]], device=device).reshape((<span class="hljs-number">1</span>, <span class="hljs-number">1</span>))<span class="hljs-comment">##output 的最后一个作为 input</span><br>    <span class="hljs-keyword">for</span> y <span class="hljs-keyword">in</span> prefix[<span class="hljs-number">1</span>:]:  <span class="hljs-comment"># Warm-up period</span><br>        _, state = net(get_input(), state)<br>        outputs.append(vocab[y])<br>    <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_preds):  <span class="hljs-comment"># Predict `num_preds` steps</span><br>        y, state = net(get_input(), state)<br>        outputs.append(<span class="hljs-built_in">int</span>(y.argmax(dim=<span class="hljs-number">1</span>).reshape(<span class="hljs-number">1</span>)))<br>    <span class="hljs-keyword">return</span> <span class="hljs-string">&#x27;&#x27;</span>.join([vocab.idx_to_token[i] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> outputs])<br></code></pre></td></tr></table></figure>

<p>试一下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">predict_ch8(<span class="hljs-string">&#x27;time traveller &#x27;</span>, <span class="hljs-number">10</span>, net, vocab, d2l.try_gpu())<br><span class="hljs-string">&#x27;time traveller knr&lt;unk&gt;knr&lt;unk&gt;kn&#x27;</span><br></code></pre></td></tr></table></figure>

<h4 id="梯度裁剪"><a href="#梯度裁剪" class="headerlink" title="梯度裁剪"></a>梯度裁剪</h4><p>当我们计算的时间步比较长的时候，由于多个矩阵相乘可能会导致梯度爆炸或梯度消失，因此在更新梯度时，如果梯度过小或过大则采取梯度裁剪的方法限制其大小：</p>
<p>$$<br>\mathbf{g} \leftarrow \min\left(1, \frac{\theta}{|\mathbf{g}|}\right) \mathbf{g}.<br>$$</p>
<p>$||g||$ 表示梯度的 L2 范数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">grad_clipping</span>(<span class="hljs-params">net, theta</span>):  <span class="hljs-comment">#@save</span><br>    <span class="hljs-string">&quot;&quot;&quot;Clip the gradient.&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(net, nn.Module):<br>        params = [p <span class="hljs-keyword">for</span> p <span class="hljs-keyword">in</span> net.parameters() <span class="hljs-keyword">if</span> p.requires_grad]<br>    <span class="hljs-keyword">else</span>:<br>        params = net.params<br>    norm = torch.sqrt(<span class="hljs-built_in">sum</span>(torch.<span class="hljs-built_in">sum</span>((p.grad ** <span class="hljs-number">2</span>)) <span class="hljs-keyword">for</span> p <span class="hljs-keyword">in</span> params))<br>    <span class="hljs-keyword">if</span> norm &gt; theta:<br>        <span class="hljs-keyword">for</span> param <span class="hljs-keyword">in</span> params:<br>            param.grad[:] *= theta / norm<br></code></pre></td></tr></table></figure>

<h4 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h4><p>RNN 的训练有几点不同：</p>
<ul>
<li><p>序列数据不同的采样方法会导致隐状态的初始化不同</p>
<ul>
<li>对于顺序采样，每个批量的时间步是相邻的，因此上一个批量的最终隐状态可以传递到下一个批量的初始隐状态，但是需要将梯度移除（<code>detach_</code>）</li>
<li>对于随机采样，每个批量不一定相邻，因此每次都需要初始化最初的隐状态</li>
</ul>
</li>
<li><p>在更新模型参数之前将梯度进行裁剪</p>
</li>
<li><p>用困惑度（perplexity）来衡量模型</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#@save</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">train_epoch_ch8</span>(<span class="hljs-params">net, train_iter, loss, updater, device, use_random_iter</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;Train a net within one epoch (defined in Chapter 8).&quot;&quot;&quot;</span><br>    state, timer = <span class="hljs-literal">None</span>, d2l.Timer()<br>    metric = d2l.Accumulator(<span class="hljs-number">2</span>)  <span class="hljs-comment"># Sum of training loss, no. of tokens</span><br>    <span class="hljs-keyword">for</span> X, Y <span class="hljs-keyword">in</span> train_iter:<br>        <span class="hljs-keyword">if</span> state <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span> <span class="hljs-keyword">or</span> use_random_iter:<br>            <span class="hljs-comment"># Initialize `state` when either it is the first iteration or</span><br>            <span class="hljs-comment"># using random sampling</span><br>            state = net.begin_state(batch_size=X.shape[<span class="hljs-number">0</span>], device=device)<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(net, nn.Module) <span class="hljs-keyword">and</span> <span class="hljs-keyword">not</span> <span class="hljs-built_in">isinstance</span>(state, <span class="hljs-built_in">tuple</span>):<br>                <span class="hljs-comment"># `state` is a tensor for `nn.GRU`</span><br>                state.detach_()<br>            <span class="hljs-keyword">else</span>:<br>                <span class="hljs-comment"># `state` is a tuple of tensors for `nn.LSTM` and</span><br>                <span class="hljs-comment"># for our custom scratch implementation</span><br>                <span class="hljs-keyword">for</span> s <span class="hljs-keyword">in</span> state:<br>                    s.detach_()<br>        y = Y.T.reshape(-<span class="hljs-number">1</span>)<br>        X, y = X.to(device), y.to(device)<br>        y_hat, state = net(X, state)<br>        l = loss(y_hat, y.long()).mean()<br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(updater, torch.optim.Optimizer):<br>            updater.zero_grad()<br>            l.backward()<br>            grad_clipping(net, <span class="hljs-number">1</span>)<br>            updater.step()<br>        <span class="hljs-keyword">else</span>:<br>            l.backward()<br>            grad_clipping(net, <span class="hljs-number">1</span>)<br>            <span class="hljs-comment"># Since the `mean` function has been invoked</span><br>            updater(batch_size=<span class="hljs-number">1</span>)<br>        metric.add(l * y.numel(), y.numel())<br>    <span class="hljs-keyword">return</span> math.exp(metric[<span class="hljs-number">0</span>] / metric[<span class="hljs-number">1</span>]), metric[<span class="hljs-number">1</span>] / timer.stop()<br></code></pre></td></tr></table></figure>

<p>接下来就可以进行训练了：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#@save</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">train_ch8</span>(<span class="hljs-params">net, train_iter, vocab, lr, num_epochs, device,</span><br><span class="hljs-params">              use_random_iter=<span class="hljs-literal">False</span></span>):<br>    <span class="hljs-string">&quot;&quot;&quot;Train a model (defined in Chapter 8).&quot;&quot;&quot;</span><br>    loss = nn.CrossEntropyLoss()<br>    animator = d2l.Animator(xlabel=<span class="hljs-string">&#x27;epoch&#x27;</span>, ylabel=<span class="hljs-string">&#x27;perplexity&#x27;</span>,<br>                            legend=[<span class="hljs-string">&#x27;train&#x27;</span>], xlim=[<span class="hljs-number">10</span>, num_epochs])<br>    <span class="hljs-comment"># Initialize</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(net, nn.Module):<br>        updater = torch.optim.SGD(net.parameters(), lr)<br>    <span class="hljs-keyword">else</span>:<br>        updater = <span class="hljs-keyword">lambda</span> batch_size: d2l.sgd(net.params, lr, batch_size)<br>    predict = <span class="hljs-keyword">lambda</span> prefix: predict_ch8(prefix, <span class="hljs-number">50</span>, net, vocab, device)<br>    <span class="hljs-comment"># Train and predict</span><br>    <span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_epochs):<br>        ppl, speed = train_epoch_ch8(<br>            net, train_iter, loss, updater, device, use_random_iter)<br>        <span class="hljs-keyword">if</span> (epoch + <span class="hljs-number">1</span>) % <span class="hljs-number">10</span> == <span class="hljs-number">0</span>:<br>            <span class="hljs-built_in">print</span>(predict(<span class="hljs-string">&#x27;time traveller&#x27;</span>))<br>            animator.add(epoch + <span class="hljs-number">1</span>, [ppl])<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;perplexity <span class="hljs-subst">&#123;ppl:<span class="hljs-number">.1</span>f&#125;</span>, <span class="hljs-subst">&#123;speed:<span class="hljs-number">.1</span>f&#125;</span> tokens/sec on <span class="hljs-subst">&#123;<span class="hljs-built_in">str</span>(device)&#125;</span>&#x27;</span>)<br>    <span class="hljs-built_in">print</span>(predict(<span class="hljs-string">&#x27;time traveller&#x27;</span>))<br>    <span class="hljs-built_in">print</span>(predict(<span class="hljs-string">&#x27;traveller&#x27;</span>))<br><br>num_epochs, lr = <span class="hljs-number">500</span>, <span class="hljs-number">1</span><br>train_ch8(net, train_iter, vocab, lr, num_epochs, d2l.try_gpu())<br></code></pre></td></tr></table></figure>

<img src="https://picgo-wutao.oss-cn-shanghai.aliyuncs.com/img/image-20220428231806-47oxqky.png" srcset="/img/loading.gif" lazyload style="zoom:67%;" />

<h4 id="Pytorch-API-实现-RNN"><a href="#Pytorch-API-实现-RNN" class="headerlink" title="Pytorch API 实现 RNN"></a>Pytorch API 实现 RNN</h4><p>导入数据：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><span class="hljs-keyword">from</span> torch.nn <span class="hljs-keyword">import</span> functional <span class="hljs-keyword">as</span> F<br><span class="hljs-keyword">from</span> d2l <span class="hljs-keyword">import</span> torch <span class="hljs-keyword">as</span> d2l<br><br>batch_size, num_steps = <span class="hljs-number">32</span>, <span class="hljs-number">35</span><br>train_iter, vocab = d2l.load_data_time_machine(batch_size, num_steps)<br></code></pre></td></tr></table></figure>

<p>使用 pytorch 的高阶 API 来构建循环神经网络需要使用 <code>nn.RNN</code> 类，实例化这个类需要提供词汇表和隐藏层的大小：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">num_hiddens = <span class="hljs-number">256</span><br>rnn_layer = nn.RNN(<span class="hljs-built_in">len</span>(vocab), num_hiddens)<br></code></pre></td></tr></table></figure>

<p>RNN 层的输入是序列 X 和初始的隐状态，因此我们需要初始化隐状态，性状是（隐藏层的数量，批量大小，隐藏层的大小）：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">state = torch.zeros((<span class="hljs-number">1</span>, batch_size, num_hiddens))<span class="hljs-comment">##一个隐藏层</span><br>state.shape<br><br>torch.Size([<span class="hljs-number">1</span>, <span class="hljs-number">32</span>, <span class="hljs-number">256</span>])<br></code></pre></td></tr></table></figure>

<p>RNN 层的输出有两个：所有中间的隐藏状态（也就是 Y）以及最后一个隐藏状态（H），要注意这里的 Y 和上面算的 Y 不一样，这里仅仅是隐状态，没有通过输出层转化，所以 Y 的最后一个元素就是输出的 状态：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python">X = torch.rand(size=(num_steps, batch_size, <span class="hljs-built_in">len</span>(vocab)))<br>Y, state_new = rnn_layer(X, state)<br>Y.shape, state_new.shape<br><br>(torch.Size([<span class="hljs-number">35</span>, <span class="hljs-number">32</span>, <span class="hljs-number">256</span>]), torch.Size([<span class="hljs-number">1</span>, <span class="hljs-number">32</span>, <span class="hljs-number">256</span>]))<br><br>torch.<span class="hljs-built_in">all</span>(Y[-<span class="hljs-number">1</span>] == state_new)<span class="hljs-comment">##判断最后一个元素是否等于输出的 state</span><br>tensor(<span class="hljs-literal">True</span>)<br></code></pre></td></tr></table></figure>

<img src="https://picgo-wutao.oss-cn-shanghai.aliyuncs.com/img/image-20220528120925-bqsgwri.png" srcset="/img/loading.gif" lazyload style="zoom:67%;" />



<p>定义整个的 RNN 类：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#@save</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">RNNModel</span>(nn.Module):<br>    <span class="hljs-string">&quot;&quot;&quot;The RNN model.&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, rnn_layer, vocab_size, **kwargs</span>):<br>        <span class="hljs-built_in">super</span>(RNNModel, self).__init__(**kwargs)<br>        self.rnn = rnn_layer<br>        self.vocab_size = vocab_size<br>        self.num_hiddens = self.rnn.hidden_size<br>        <span class="hljs-comment"># If the RNN is bidirectional (to be introduced later),</span><br>        <span class="hljs-comment"># `num_directions` should be 2, else it should be 1.</span><br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> self.rnn.bidirectional:<br>            self.num_directions = <span class="hljs-number">1</span><br>            self.linear = nn.Linear(self.num_hiddens, self.vocab_size)<br>        <span class="hljs-keyword">else</span>:<br>            self.num_directions = <span class="hljs-number">2</span><br>            self.linear = nn.Linear(self.num_hiddens * <span class="hljs-number">2</span>, self.vocab_size)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, inputs, state</span>):<br>        X = F.one_hot(inputs.T.long(), self.vocab_size)<br>        X = X.to(torch.float32)<br>        Y, state = self.rnn(X, state)<br>        <span class="hljs-comment"># The fully connected layer will first change the shape of `Y` to</span><br>        <span class="hljs-comment"># (`num_steps` * `batch_size`, `num_hiddens`). Its output shape is</span><br>        <span class="hljs-comment"># (`num_steps` * `batch_size`, `vocab_size`).</span><br>        output = self.linear(Y.reshape((-<span class="hljs-number">1</span>, Y.shape[-<span class="hljs-number">1</span>])))<br>        <span class="hljs-keyword">return</span> output, state<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">begin_state</span>(<span class="hljs-params">self, device, batch_size=<span class="hljs-number">1</span></span>):<br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> <span class="hljs-built_in">isinstance</span>(self.rnn, nn.LSTM):<br>            <span class="hljs-comment"># `nn.GRU` takes a tensor as hidden state</span><br>            <span class="hljs-keyword">return</span>  torch.zeros((self.num_directions * self.rnn.num_layers,<br>                                 batch_size, self.num_hiddens),<br>                                device=device)<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-comment"># `nn.LSTM` takes a tuple of hidden states</span><br>            <span class="hljs-keyword">return</span> (torch.zeros((<br>                self.num_directions * self.rnn.num_layers,<br>                batch_size, self.num_hiddens), device=device),<br>                    torch.zeros((<br>                        self.num_directions * self.rnn.num_layers,<br>                        batch_size, self.num_hiddens), device=device))<br></code></pre></td></tr></table></figure>

<p>训练和预测：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python">device = d2l.try_gpu()<br>net = RNNModel(rnn_layer, vocab_size=<span class="hljs-built_in">len</span>(vocab))<br>net = net.to(device)<br>d2l.predict_ch8(<span class="hljs-string">&#x27;time traveller&#x27;</span>, <span class="hljs-number">10</span>, net, vocab, device)<br><br><span class="hljs-string">&#x27;time travellerlysysssyss&#x27;</span><br><span class="hljs-comment">##训练</span><br>num_epochs, lr = <span class="hljs-number">500</span>, <span class="hljs-number">1</span><br>d2l.train_ch8(net, train_iter, vocab, lr, num_epochs, device)<br></code></pre></td></tr></table></figure>

<img src="https://picgo-wutao.oss-cn-shanghai.aliyuncs.com/img/image-20220528185452-pk22g58.png" srcset="/img/loading.gif" lazyload style="zoom:67%;" />

<h2 id="经典循环神经网络"><a href="#经典循环神经网络" class="headerlink" title="经典循环神经网络"></a>经典循环神经网络</h2><h3 id="GRU"><a href="#GRU" class="headerlink" title="GRU"></a>GRU</h3><p>前面的 RNN 在计算每个输入时都会考虑包含之前所有输入的隐状态，但是对于一个序列而已不是每一个部分都是同等重要的，有些时候需要更关注某些观测值，有时则需要跳过某些观测值。GRU 通过在 RNN 的基础上引入两个门控单元：重置门（reset gate ，<strong>R</strong>）和更新门（update gate，<strong>Z</strong>）来决定<strong>当前的隐状态的更新是否和当前的输入相关</strong>：</p>
<img src="https://picgo-wutao.oss-cn-shanghai.aliyuncs.com/img/image-20220528212128-ujzx5w5.png" srcset="/img/loading.gif" lazyload style="zoom:67%;" />



<p>这两个门其实就是有着 sigmoid 激活函数的全连接层，接着通过重置门我们可以得到候选隐状态：</p>
<img src="https://picgo-wutao.oss-cn-shanghai.aliyuncs.com/img/image-20220528212419-og1vwiw.png" srcset="/img/loading.gif" lazyload style="zoom:67%;" />



<p>这个 $\odot$ 表示按元素相乘，因为这两个门的结果都是经过  sigmoid 函数的，也就是在 0 到 1 之间，如果 R 为 0，那么这个候选隐状态就没有考虑之前的隐状态，相当于将当前输入输进一个 MLP 得到的结果；如果 R 为 1，那么这个候选隐状态就和之前 RNN 得到的结果是一样的了。</p>
<p>接着基于候选隐状态和更新门得到最终的隐状态：</p>
<img src="https://picgo-wutao.oss-cn-shanghai.aliyuncs.com/img/image-20220528212906-0l3b8h1.png" srcset="/img/loading.gif" lazyload style="zoom:67%;" />



<p>因此这个 Z 决定了如何去更新当前的隐状态：如果 Z 为 0，则候选隐状态为当前的隐状态，如果 Z 为 1，则完全不考虑当前的输入。R 是对之前信息的遗忘程度，Z 是对当前信息的关注程度。</p>
<h4 id="GRU-实现"><a href="#GRU-实现" class="headerlink" title="GRU 实现"></a>GRU 实现</h4><p>读入数据：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><span class="hljs-keyword">from</span> d2l <span class="hljs-keyword">import</span> torch <span class="hljs-keyword">as</span> d2l<br><br>batch_size, num_steps = <span class="hljs-number">32</span>, <span class="hljs-number">35</span><br>train_iter, vocab = d2l.load_data_time_machine(batch_size, num_steps)<br></code></pre></td></tr></table></figure>

<p>高斯分布初始化参数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_params</span>(<span class="hljs-params">vocab_size, num_hiddens, device</span>):<br>    num_inputs = num_outputs = vocab_size<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">normal</span>(<span class="hljs-params">shape</span>):<br>        <span class="hljs-keyword">return</span> torch.randn(size=shape, device=device)*<span class="hljs-number">0.01</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">three</span>():<br>        <span class="hljs-keyword">return</span> (normal((num_inputs, num_hiddens)),<br>                normal((num_hiddens, num_hiddens)),<br>                torch.zeros(num_hiddens, device=device))<br><br>    W_xz, W_hz, b_z = three()  <span class="hljs-comment"># Update gate parameters</span><br>    W_xr, W_hr, b_r = three()  <span class="hljs-comment"># Reset gate parameters</span><br>    W_xh, W_hh, b_h = three()  <span class="hljs-comment"># Candidate hidden state parameters</span><br>    <span class="hljs-comment"># Output layer parameters</span><br>    W_hq = normal((num_hiddens, num_outputs))<br>    b_q = torch.zeros(num_outputs, device=device)<br>    <span class="hljs-comment"># Attach gradients</span><br>    params = [W_xz, W_hz, b_z, W_xr, W_hr, b_r, W_xh, W_hh, b_h, W_hq, b_q]<br>    <span class="hljs-keyword">for</span> param <span class="hljs-keyword">in</span> params:<br>        param.requires_grad_(<span class="hljs-literal">True</span>)<br>    <span class="hljs-keyword">return</span> params<br><br><span class="hljs-comment">##初始化隐状态</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">init_gru_state</span>(<span class="hljs-params">batch_size, num_hiddens, device</span>):<br>    <span class="hljs-keyword">return</span> (torch.zeros((batch_size, num_hiddens), device=device), )<br></code></pre></td></tr></table></figure>

<p>定义模型：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">gru</span>(<span class="hljs-params">inputs, state, params</span>):<br>    W_xz, W_hz, b_z, W_xr, W_hr, b_r, W_xh, W_hh, b_h, W_hq, b_q = params<br>    H, = state<br>    outputs = []<br>    <span class="hljs-keyword">for</span> X <span class="hljs-keyword">in</span> inputs:<br>        Z = torch.sigmoid((X @ W_xz) + (H @ W_hz) + b_z)<br>        R = torch.sigmoid((X @ W_xr) + (H @ W_hr) + b_r)<br>        H_tilda = torch.tanh((X @ W_xh) + ((R * H) @ W_hh) + b_h)<br>        H = Z * H + (<span class="hljs-number">1</span> - Z) * H_tilda<br>        Y = H @ W_hq + b_q<br>        outputs.append(Y)<br>    <span class="hljs-keyword">return</span> torch.cat(outputs, dim=<span class="hljs-number">0</span>), (H,)<br></code></pre></td></tr></table></figure>

<p>训练，预测：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">vocab_size, num_hiddens, device = <span class="hljs-built_in">len</span>(vocab), <span class="hljs-number">256</span>, d2l.try_gpu()<br>num_epochs, lr = <span class="hljs-number">500</span>, <span class="hljs-number">1</span><br>model = d2l.RNNModelScratch(<span class="hljs-built_in">len</span>(vocab), num_hiddens, device, get_params,<br>                            init_gru_state, gru)<br>d2l.train_ch8(model, train_iter, vocab, lr, num_epochs, device)<br></code></pre></td></tr></table></figure>

<p>也可以使用 pytorch 的 API 来实现：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">num_inputs = vocab_size<br>gru_layer = nn.GRU(num_inputs, num_hiddens)<br>model = d2l.RNNModel(gru_layer, <span class="hljs-built_in">len</span>(vocab))<br>model = model.to(device)<br>d2l.train_ch8(model, train_iter, vocab, lr, num_epochs, device)<br></code></pre></td></tr></table></figure>

<img src="https://picgo-wutao.oss-cn-shanghai.aliyuncs.com/img/image-20220528214618-m3fy1kp.png" srcset="/img/loading.gif" lazyload style="zoom:67%;" />

<h3 id="LSTM"><a href="#LSTM" class="headerlink" title="LSTM"></a>LSTM</h3><p>LSTM 和 GRU 的很多设计类似，但是比 GRU 早了 20 年，LSTM 引入了记忆单元（memory cell），和隐状态的大小一样，也可以看作是另一种隐状态。LSTM 使用了 3 个门控单元：</p>
<img src="https://picgo-wutao.oss-cn-shanghai.aliyuncs.com/img/image-20220528223937-9r308oa.png" srcset="/img/loading.gif" lazyload style="zoom:50%;" />



<p>这些门和 GRU 里面的一样，都是由 sigmoid 激活函数的全连接网络；LSTM 还有一个候选记忆单元：</p>
<img src="https://picgo-wutao.oss-cn-shanghai.aliyuncs.com/img/image-20220528224149-bz5bc3g.png" srcset="/img/loading.gif" lazyload style="zoom:50%;" />



<p>这个所谓的候选记忆单元和之前的 RNN 里面的隐状态的计算方式是一样的，没有用到门控，因此这个候选记忆单元相当于储存了当前的记忆。除了隐状态之外，LSTM 还有记忆单元 C：</p>
<img src="https://picgo-wutao.oss-cn-shanghai.aliyuncs.com/img/image-20220528224353-sf5ih2j.png" srcset="/img/loading.gif" lazyload style="zoom:50%;" />



<p>当前的记忆单元的计算涉及到上一个记忆单元，候选记忆单元以及当前的两个门控单元，注意这里的两个门控单元是独立的，而不像前面 GRU 中一个是 Z 另一个就是 1-Z，也就是说可以同时用到前一个记忆单元和当前的记忆单元，也可以都不用（相当于重置了记忆），接着就是隐状态的更新：</p>
<img src="https://picgo-wutao.oss-cn-shanghai.aliyuncs.com/img/image-20220528224849-i85438t.png" srcset="/img/loading.gif" lazyload style="zoom:50%;" />



<p>tanh 的目的是对 C 进行缩放，因为从上面计算记忆单元的式子来看，得到的结果不一定处于 -1~1 之间。如果这个输出门为 1，那么隐状态就包含了前一个记忆，前一个隐状态，以及当前的输入，如果为 0，则重置隐状态。总结一下：遗忘门控制着对之前记忆的保留程度，输入门控制着当前记忆的保留程度，输出门则控制着对前两个门的计算结果的输出</p>
<h4 id="LSTM-的实现"><a href="#LSTM-的实现" class="headerlink" title="LSTM 的实现"></a>LSTM 的实现</h4><p>导入数据：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><span class="hljs-keyword">from</span> d2l <span class="hljs-keyword">import</span> torch <span class="hljs-keyword">as</span> d2l<br><br>batch_size, num_steps = <span class="hljs-number">32</span>, <span class="hljs-number">35</span><br>train_iter, vocab = d2l.load_data_time_machine(batch_size, num_steps)<br></code></pre></td></tr></table></figure>

<p>初始化参数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_lstm_params</span>(<span class="hljs-params">vocab_size, num_hiddens, device</span>):<br>    num_inputs = num_outputs = vocab_size<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">normal</span>(<span class="hljs-params">shape</span>):<br>        <span class="hljs-keyword">return</span> torch.randn(size=shape, device=device)*<span class="hljs-number">0.01</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">three</span>():<br>        <span class="hljs-keyword">return</span> (normal((num_inputs, num_hiddens)),<br>                normal((num_hiddens, num_hiddens)),<br>                torch.zeros(num_hiddens, device=device))<br><br>    W_xi, W_hi, b_i = three()  <span class="hljs-comment"># Input gate parameters</span><br>    W_xf, W_hf, b_f = three()  <span class="hljs-comment"># Forget gate parameters</span><br>    W_xo, W_ho, b_o = three()  <span class="hljs-comment"># Output gate parameters</span><br>    W_xc, W_hc, b_c = three()  <span class="hljs-comment"># Candidate memory cell parameters</span><br>    <span class="hljs-comment"># Output layer parameters</span><br>    W_hq = normal((num_hiddens, num_outputs))<br>    b_q = torch.zeros(num_outputs, device=device)<br>    <span class="hljs-comment"># Attach gradients</span><br>    params = [W_xi, W_hi, b_i, W_xf, W_hf, b_f, W_xo, W_ho, b_o, W_xc, W_hc,<br>              b_c, W_hq, b_q]<br>    <span class="hljs-keyword">for</span> param <span class="hljs-keyword">in</span> params:<br>        param.requires_grad_(<span class="hljs-literal">True</span>)<br>    <span class="hljs-keyword">return</span> params<br><br><span class="hljs-comment">##初始化状态，这里有状态和记忆单元</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">init_lstm_state</span>(<span class="hljs-params">batch_size, num_hiddens, device</span>):<br>    <span class="hljs-keyword">return</span> (torch.zeros((batch_size, num_hiddens), device=device),<br>            torch.zeros((batch_size, num_hiddens), device=device))<br></code></pre></td></tr></table></figure>

<p>定义模型：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">lstm</span>(<span class="hljs-params">inputs, state, params</span>):<br>    [W_xi, W_hi, b_i, W_xf, W_hf, b_f, W_xo, W_ho, b_o, W_xc, W_hc, b_c,<br>     W_hq, b_q] = params<br>    (H, C) = state<br>    outputs = []<br>    <span class="hljs-keyword">for</span> X <span class="hljs-keyword">in</span> inputs:<br>        I = torch.sigmoid((X @ W_xi) + (H @ W_hi) + b_i)<br>        F = torch.sigmoid((X @ W_xf) + (H @ W_hf) + b_f)<br>        O = torch.sigmoid((X @ W_xo) + (H @ W_ho) + b_o)<br>        C_tilda = torch.tanh((X @ W_xc) + (H @ W_hc) + b_c)<br>        C = F * C + I * C_tilda<br>        H = O * torch.tanh(C)<br>        Y = (H @ W_hq) + b_q<span class="hljs-comment">##O不参与输出计算</span><br>        outputs.append(Y)<br>    <span class="hljs-keyword">return</span> torch.cat(outputs, dim=<span class="hljs-number">0</span>), (H, C)<br></code></pre></td></tr></table></figure>

<p>训练和预测：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">vocab_size, num_hiddens, device = <span class="hljs-built_in">len</span>(vocab), <span class="hljs-number">256</span>, d2l.try_gpu()<br>num_epochs, lr = <span class="hljs-number">500</span>, <span class="hljs-number">1</span><br>model = d2l.RNNModelScratch(<span class="hljs-built_in">len</span>(vocab), num_hiddens, device, get_lstm_params,<br>                            init_lstm_state, lstm)<br>d2l.train_ch8(model, train_iter, vocab, lr, num_epochs, device)<br></code></pre></td></tr></table></figure>

<p>也可以直接使用 Pytorch 的 API：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">num_inputs = vocab_size<br>lstm_layer = nn.LSTM(num_inputs, num_hiddens)<br>model = d2l.RNNModel(lstm_layer, <span class="hljs-built_in">len</span>(vocab))<br>model = model.to(device)<br>d2l.train_ch8(model, train_iter, vocab, lr, num_epochs, device)<br></code></pre></td></tr></table></figure>

<img src="https://picgo-wutao.oss-cn-shanghai.aliyuncs.com/img/image-20220528230544-s3plklg.png" srcset="/img/loading.gif" lazyload style="zoom:67%;" />

<h3 id="深度循环神经网络"><a href="#深度循环神经网络" class="headerlink" title="深度循环神经网络"></a>深度循环神经网络</h3><p>深度循环神经网络就是使用更多的隐藏层，每个隐藏层接受上一个隐藏层的输入，输出是新的隐状态，这个新的隐状态一方面向下一步传递，另一方面向该步的下一个隐藏层传递：</p>
<img src="https://picgo-wutao.oss-cn-shanghai.aliyuncs.com/img/image-20220529083050-v2y45ji.png" srcset="/img/loading.gif" lazyload style="zoom:50%;" />



<p>代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">##数据</span><br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><span class="hljs-keyword">from</span> d2l <span class="hljs-keyword">import</span> torch <span class="hljs-keyword">as</span> d2l<br><br>batch_size, num_steps = <span class="hljs-number">32</span>, <span class="hljs-number">35</span><br>train_iter, vocab = d2l.load_data_time_machine(batch_size, num_steps)<br><br><span class="hljs-comment">##参数和模型</span><br>vocab_size, num_hiddens, num_layers = <span class="hljs-built_in">len</span>(vocab), <span class="hljs-number">256</span>, <span class="hljs-number">2</span><br>num_inputs = vocab_size<br>device = d2l.try_gpu()<br>lstm_layer = nn.LSTM(num_inputs, num_hiddens, num_layers)<br>model = d2l.RNNModel(lstm_layer, <span class="hljs-built_in">len</span>(vocab))<br>model = model.to(device)<br><br><span class="hljs-comment">##预测和训练</span><br>num_epochs, lr = <span class="hljs-number">500</span>, <span class="hljs-number">2</span><br>d2l.train_ch8(model, train_iter, vocab, lr, num_epochs, device)<br></code></pre></td></tr></table></figure>

<h3 id="双向循环神经网络"><a href="#双向循环神经网络" class="headerlink" title="双向循环神经网络"></a>双向循环神经网络</h3><p>双向循环神经网络通过加入隐状态的反向传递，从而利用 “未来” 的信息（因此不适宜做推理任务，因为在推理预测任务中模型看不到未来的观测）：</p>
<img src="https://picgo-wutao.oss-cn-shanghai.aliyuncs.com/img/image-20220529120831-5709iik.png" srcset="/img/loading.gif" lazyload style="zoom:67%;" />



<p>代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><span class="hljs-keyword">from</span> d2l <span class="hljs-keyword">import</span> torch <span class="hljs-keyword">as</span> d2l<br><br><span class="hljs-comment"># Load data</span><br>batch_size, num_steps, device = <span class="hljs-number">32</span>, <span class="hljs-number">35</span>, d2l.try_gpu()<br>train_iter, vocab = d2l.load_data_time_machine(batch_size, num_steps)<br><span class="hljs-comment"># Define the bidirectional LSTM model by setting `bidirectional=True`</span><br>vocab_size, num_hiddens, num_layers = <span class="hljs-built_in">len</span>(vocab), <span class="hljs-number">256</span>, <span class="hljs-number">2</span><br>num_inputs = vocab_size<br>lstm_layer = nn.LSTM(num_inputs, num_hiddens, num_layers, bidirectional=<span class="hljs-literal">True</span>)<br>model = d2l.RNNModel(lstm_layer, <span class="hljs-built_in">len</span>(vocab))<br>model = model.to(device)<br><span class="hljs-comment"># Train the model</span><br>num_epochs, lr = <span class="hljs-number">50</span>, <span class="hljs-number">1</span><br>d2l.train_ch8(model, train_iter, vocab, lr, num_epochs, device)<br></code></pre></td></tr></table></figure>

<img src="https://picgo-wutao.oss-cn-shanghai.aliyuncs.com/img/image-20220529120858-y4lcxvg.png" srcset="/img/loading.gif" lazyload style="zoom:67%;" />

<h3 id="机器翻译和数据集"><a href="#机器翻译和数据集" class="headerlink" title="机器翻译和数据集"></a>机器翻译和数据集</h3><p>机器翻译也就是从一个序列转化成另一个序列，属于一种序列转化模型（sequence transduction），输入和输出都是长度可变的序列，因此和之前讲的语言模型的数据预处理过程有不同的地方。</p>
<h4 id="数据下载和预处理"><a href="#数据下载和预处理" class="headerlink" title="数据下载和预处理"></a>数据下载和预处理</h4><p>这里使用的数据是来自 Tatoeba 项目的双语句子对（英语对法语），每一行是一句英语和对应的法语翻译，因此在这个数据集中英语是源语言（source），法语是目标语言（target）：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> d2l <span class="hljs-keyword">import</span> torch <span class="hljs-keyword">as</span> d2l<br><br><span class="hljs-comment">##下载数据</span><br><span class="hljs-comment">#@save</span><br>d2l.DATA_HUB[<span class="hljs-string">&#x27;fra-eng&#x27;</span>] = (d2l.DATA_URL + <span class="hljs-string">&#x27;fra-eng.zip&#x27;</span>,<br>                           <span class="hljs-string">&#x27;94646ad1522d915e7b0f9296181140edcf86a4f5&#x27;</span>)<br><br><span class="hljs-comment">##下载数据http://d2l-data.s3-accelerate.amazonaws.com/fra-eng.zip</span><br><span class="hljs-comment">##解压</span><br>!unzip fra-eng.<span class="hljs-built_in">zip</span><br><span class="hljs-comment">#@save</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">read_data_nmt</span>(<span class="hljs-params">data_dir</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;Load the English-French dataset.&quot;&quot;&quot;</span><br>    <span class="hljs-comment">#data_dir = d2l.download_extract(&#x27;fra-eng&#x27;)##已经下载了</span><br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(os.path.join(data_dir, <span class="hljs-string">&#x27;fra.txt&#x27;</span>), <span class="hljs-string">&#x27;r&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>        <span class="hljs-keyword">return</span> f.read()<br><br>raw_text = read_data_nmt(<span class="hljs-string">&quot;./fra-eng/&quot;</span>)<br><span class="hljs-built_in">print</span>(raw_text[:<span class="hljs-number">75</span>])<br><br>Go.	Va !<br>Hi.	Salut !<br>Run!	Cours !<br>Run!	Courez !<br>Who?	Qui ?<br>Wow!	Ça alors !<br></code></pre></td></tr></table></figure>

<p>接下来需要进行一些预处理的操作，比如将不换行空格转化成空格，将大写转化成小写，在次和标点之间插入空格：</p>
<blockquote>
<p>编辑器一般会把自动换行放在空格字符处。但是，有些文本内容在排版时不适合被放在连续的一行行尾与下一行行首。例如：“100 km”，就不应该在其中间的那个空格处换行。所以编辑器应该在”100”与”km”之间放置一个“不换行空格”</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#@save</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">preprocess_nmt</span>(<span class="hljs-params">text</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;Preprocess the English-French dataset.&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">no_space</span>(<span class="hljs-params">char, prev_char</span>):<br>        <span class="hljs-keyword">return</span> char <span class="hljs-keyword">in</span> <span class="hljs-built_in">set</span>(<span class="hljs-string">&#x27;,.!?&#x27;</span>) <span class="hljs-keyword">and</span> prev_char != <span class="hljs-string">&#x27; &#x27;</span><br><br>    <span class="hljs-comment"># Replace non-breaking space with space, and convert uppercase letters to</span><br>    <span class="hljs-comment"># lowercase ones</span><br>    text = text.replace(<span class="hljs-string">&#x27;\u202f&#x27;</span>, <span class="hljs-string">&#x27; &#x27;</span>).replace(<span class="hljs-string">&#x27;\xa0&#x27;</span>, <span class="hljs-string">&#x27; &#x27;</span>).lower()<br>    <span class="hljs-comment"># Insert space between words and punctuation marks</span><br>    <span class="hljs-comment">##不是第一个字符，该字符为标点且前一个字符不是空格，那么就在该字符前面插入一个空格</span><br>    out = [<span class="hljs-string">&#x27; &#x27;</span> + char <span class="hljs-keyword">if</span> i &gt; <span class="hljs-number">0</span> <span class="hljs-keyword">and</span> no_space(char, text[i - <span class="hljs-number">1</span>]) <span class="hljs-keyword">else</span> char<br>           <span class="hljs-keyword">for</span> i, char <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(text)]<br>    <span class="hljs-keyword">return</span> <span class="hljs-string">&#x27;&#x27;</span>.join(out)<br><br>text = preprocess_nmt(raw_text)<br><span class="hljs-built_in">print</span>(text[:<span class="hljs-number">80</span>])<br><br>go .	va !<br>hi .	salut !<br>run !	cours !<br>run !	courez !<br>who ?	qui ?<br>wow !	ça alors !<br></code></pre></td></tr></table></figure>

<p>和之前一样，这里也需要进行 Tokenization，只不过之前是以字符进行 Tokenization，在机器翻译中可以用词来 Tokenization：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#@save</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">tokenize_nmt</span>(<span class="hljs-params">text, num_examples=<span class="hljs-literal">None</span></span>):<br>    <span class="hljs-string">&quot;&quot;&quot;Tokenize the English-French dataset.&quot;&quot;&quot;</span><br>    source, target = [], []<br>    <span class="hljs-keyword">for</span> i, line <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(text.split(<span class="hljs-string">&#x27;\n&#x27;</span>)):<br>        <span class="hljs-keyword">if</span> num_examples <span class="hljs-keyword">and</span> i &gt; num_examples:<br>            <span class="hljs-keyword">break</span><br>        parts = line.split(<span class="hljs-string">&#x27;\t&#x27;</span>)<br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(parts) == <span class="hljs-number">2</span>:<br>            source.append(parts[<span class="hljs-number">0</span>].split(<span class="hljs-string">&#x27; &#x27;</span>))<br>            target.append(parts[<span class="hljs-number">1</span>].split(<span class="hljs-string">&#x27; &#x27;</span>))<br>     <span class="hljs-keyword">return</span> source, target<br><br>source, target = tokenize_nmt(text)<br>source[:<span class="hljs-number">6</span>], target[:<span class="hljs-number">6</span>]<br><br>go .	va !<br>hi .	salut !<br>run !	cours !<br>run !	courez !<br>who ?	qui ?<br>wow !	ça alors !<br></code></pre></td></tr></table></figure>

<p>由于机器翻译数据集由一对序列构成，因此我们需要对这一对语言构建两个词汇表，对以词为基础的Tokenization来说，词汇表的大小要比字符的Tokenization大得多（因为字符只有26个），所以将出现频次小于 2 的词弄成 <code>&lt;unk&gt;</code> 的 token，另外还要加上一些特殊的 token ，如 <code>padding</code> (使得小批量中的序列长度一致)，<code>&lt;bos&gt;</code> ，<code>&lt;eos&gt;</code> ：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">src_vocab = d2l.Vocab(source, min_freq=<span class="hljs-number">2</span>,<br>                      reserved_tokens=[<span class="hljs-string">&#x27;&lt;pad&gt;&#x27;</span>, <span class="hljs-string">&#x27;&lt;bos&gt;&#x27;</span>, <span class="hljs-string">&#x27;&lt;eos&gt;&#x27;</span>])<br><span class="hljs-built_in">len</span>(src_vocab)<br><br><span class="hljs-number">10012</span><br></code></pre></td></tr></table></figure>

<p>前面在语言模型中，一个小批量中的序列长度都是 <code>num_steps</code> ，在机器翻译中，每个实例都是一对句子，并且句子的长度还可能不一样，为了计算效率，仍然需要小批量的训练模型，因此在机器翻译中还是以 <code>num_steps</code> 来定义小批量中序列的长度，如果一个文本序列比 <code>num_steps</code> 短，那么就在末尾添加 <code>&lt;pad&gt;</code> 来使得长度等于 <code>num_steps</code>，如果比 <code>num_steps</code> 长，那么就直接截断：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#@save</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">truncate_pad</span>(<span class="hljs-params">line, num_steps, padding_token</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;Truncate or pad sequences.&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(line) &gt; num_steps:<br>        <span class="hljs-keyword">return</span> line[:num_steps]  <span class="hljs-comment"># Truncate</span><br>    <span class="hljs-keyword">return</span> line + [padding_token] * (num_steps - <span class="hljs-built_in">len</span>(line))  <span class="hljs-comment"># Pad</span><br><br>truncate_pad(src_vocab[source[<span class="hljs-number">0</span>]], <span class="hljs-number">10</span>, src_vocab[<span class="hljs-string">&#x27;&lt;pad&gt;&#x27;</span>])<br><br>[<span class="hljs-number">47</span>, <span class="hljs-number">4</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>]<br></code></pre></td></tr></table></figure>

<p> 还需要在每个句子的结尾用 <code>&lt;eos&gt;</code> 表示句子的结束，当模型预测出一个 <code>&lt;eos&gt;</code> 时表示这个句子该结束了；另外还返回了每个句子的实际长度（除去 <code>&lt;pad&gt;</code> token），这个信息在后面的模型中会用到：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#@save</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">build_array_nmt</span>(<span class="hljs-params">lines, vocab, num_steps</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;Transform text sequences of machine translation into minibatches.&quot;&quot;&quot;</span><br>    lines = [vocab[l] <span class="hljs-keyword">for</span> l <span class="hljs-keyword">in</span> lines]<br>    lines = [l + [vocab[<span class="hljs-string">&#x27;&lt;eos&gt;&#x27;</span>]] <span class="hljs-keyword">for</span> l <span class="hljs-keyword">in</span> lines]<br>    array = torch.tensor([truncate_pad(<br>        l, num_steps, vocab[<span class="hljs-string">&#x27;&lt;pad&gt;&#x27;</span>]) <span class="hljs-keyword">for</span> l <span class="hljs-keyword">in</span> lines])<br>    valid_len = (array != vocab[<span class="hljs-string">&#x27;&lt;pad&gt;&#x27;</span>]).<span class="hljs-built_in">type</span>(torch.int32).<span class="hljs-built_in">sum</span>(<span class="hljs-number">1</span>)<br>    <span class="hljs-keyword">return</span> array, valid_len<br></code></pre></td></tr></table></figure>

<p>最后将上面这些函数放到一起：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#@save</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">load_data_nmt</span>(<span class="hljs-params">batch_size, num_steps, num_examples=<span class="hljs-number">600</span></span>):<br>    <span class="hljs-string">&quot;&quot;&quot;Return the iterator and the vocabularies of the translation dataset.&quot;&quot;&quot;</span><br>    text = preprocess_nmt(read_data_nmt(<span class="hljs-string">&quot;fra-eng/&quot;</span>))<br>    source, target = tokenize_nmt(text, num_examples)<br>    src_vocab = d2l.Vocab(source, min_freq=<span class="hljs-number">2</span>,<br>                          reserved_tokens=[<span class="hljs-string">&#x27;&lt;pad&gt;&#x27;</span>, <span class="hljs-string">&#x27;&lt;bos&gt;&#x27;</span>, <span class="hljs-string">&#x27;&lt;eos&gt;&#x27;</span>])<br>    tgt_vocab = d2l.Vocab(target, min_freq=<span class="hljs-number">2</span>,<br>                          reserved_tokens=[<span class="hljs-string">&#x27;&lt;pad&gt;&#x27;</span>, <span class="hljs-string">&#x27;&lt;bos&gt;&#x27;</span>, <span class="hljs-string">&#x27;&lt;eos&gt;&#x27;</span>])<br>    src_array, src_valid_len = build_array_nmt(source, src_vocab, num_steps)<br>    tgt_array, tgt_valid_len = build_array_nmt(target, tgt_vocab, num_steps)<br>    data_arrays = (src_array, src_valid_len, tgt_array, tgt_valid_len)<br>    data_iter = d2l.load_array(data_arrays, batch_size)<br>    <span class="hljs-keyword">return</span> data_iter, src_vocab, tgt_vocab<br><br><span class="hljs-comment">##测试一下</span><br>train_iter, src_vocab, tgt_vocab = load_data_nmt(batch_size=<span class="hljs-number">2</span>, num_steps=<span class="hljs-number">8</span>)<br><span class="hljs-keyword">for</span> X, X_valid_len, Y, Y_valid_len <span class="hljs-keyword">in</span> train_iter:<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;X:&#x27;</span>, X.<span class="hljs-built_in">type</span>(torch.int32))<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;valid lengths for X:&#x27;</span>, X_valid_len)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Y:&#x27;</span>, Y.<span class="hljs-built_in">type</span>(torch.int32))<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;valid lengths for Y:&#x27;</span>, Y_valid_len)<br>    <span class="hljs-keyword">break</span><br><br>X: tensor([[ <span class="hljs-number">12</span>, <span class="hljs-number">131</span>, <span class="hljs-number">132</span>,   <span class="hljs-number">4</span>,   <span class="hljs-number">3</span>,   <span class="hljs-number">1</span>,   <span class="hljs-number">1</span>,   <span class="hljs-number">1</span>],<br>        [ <span class="hljs-number">68</span>,  <span class="hljs-number">60</span>,   <span class="hljs-number">4</span>,   <span class="hljs-number">3</span>,   <span class="hljs-number">1</span>,   <span class="hljs-number">1</span>,   <span class="hljs-number">1</span>,   <span class="hljs-number">1</span>]], dtype=torch.int32)<br>valid lengths <span class="hljs-keyword">for</span> X: tensor([<span class="hljs-number">5</span>, <span class="hljs-number">4</span>])<br>Y: tensor([[<span class="hljs-number">44</span>,  <span class="hljs-number">0</span>,  <span class="hljs-number">4</span>,  <span class="hljs-number">3</span>,  <span class="hljs-number">1</span>,  <span class="hljs-number">1</span>,  <span class="hljs-number">1</span>,  <span class="hljs-number">1</span>],<br>        [<span class="hljs-number">64</span>, <span class="hljs-number">53</span>,  <span class="hljs-number">4</span>,  <span class="hljs-number">3</span>,  <span class="hljs-number">1</span>,  <span class="hljs-number">1</span>,  <span class="hljs-number">1</span>,  <span class="hljs-number">1</span>]], dtype=torch.int32)<br>valid lengths <span class="hljs-keyword">for</span> Y: tensor([<span class="hljs-number">4</span>, <span class="hljs-number">4</span>])<br></code></pre></td></tr></table></figure>

<h3 id="编码-解码架构"><a href="#编码-解码架构" class="headerlink" title="编码-解码架构"></a>编码-解码架构</h3><p>对于输入和输出都是可变长度的序列数据，我们可以设计一个有两个元素的模型架构来处理这种类型的数据：</p>
<img src="https://picgo-wutao.oss-cn-shanghai.aliyuncs.com/img/image-20220601160137-mx947ou.png" srcset="/img/loading.gif" lazyload style="zoom:67%;" />



<p>第一个组件是编码器（encoder）：输入是可变长度的序列，输出是固定性状的中间状态；第二个组件是解码器（edcoder）：输入是 encoder 生成的状态，输出是可变长度的序列，这个架构就是编码-解码架构。</p>
<p>代码（架构，不涉及具体实现）：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><br><span class="hljs-comment">##编码器</span><br><span class="hljs-comment">#@save</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Encoder</span>(nn.Module):<br>    <span class="hljs-string">&quot;&quot;&quot;The base encoder interface for the encoder-decoder architecture.&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, **kwargs</span>):<br>        <span class="hljs-built_in">super</span>(Encoder, self).__init__(**kwargs)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, X, *args</span>):<br>        <span class="hljs-keyword">raise</span> NotImplementedError<br></code></pre></td></tr></table></figure>

<p>在 decoder 中需要一个额外的函数（<code>init_state</code>）来将 encoder 的输出转化成状态，这一步可能需要一些其他的输入（比如前面提到的序列除去 padding 的有效长度）：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#@save</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Decoder</span>(nn.Module):<br>    <span class="hljs-string">&quot;&quot;&quot;The base decoder interface for the encoder-decoder architecture.&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, **kwargs</span>):<br>        <span class="hljs-built_in">super</span>(Decoder, self).__init__(**kwargs)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">init_state</span>(<span class="hljs-params">self, enc_outputs, *args</span>):<br>        <span class="hljs-keyword">raise</span> NotImplementedError<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, X, state</span>):<br>        <span class="hljs-keyword">raise</span> NotImplementedError<br></code></pre></td></tr></table></figure>

<p>结合两者：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#@save</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">EncoderDecoder</span>(nn.Module):<br>    <span class="hljs-string">&quot;&quot;&quot;The base class for the encoder-decoder architecture.&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, encoder, decoder, **kwargs</span>):<br>        <span class="hljs-built_in">super</span>(EncoderDecoder, self).__init__(**kwargs)<br>        self.encoder = encoder<br>        self.decoder = decoder<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, enc_X, dec_X, *args</span>):<br>        enc_outputs = self.encoder(enc_X, *args)<br>        dec_state = self.decoder.init_state(enc_outputs, *args)<br>        <span class="hljs-keyword">return</span> self.decoder(dec_X, dec_state)<br></code></pre></td></tr></table></figure>

<h3 id="Seq2seq-模型"><a href="#Seq2seq-模型" class="headerlink" title="Seq2seq 模型"></a>Seq2seq 模型</h3><p>Seq2seq 模型就是上面说的编码-解码架构的一个实例：encoder 和 decoder 都是 RNN。</p>
<img src="https://picgo-wutao.oss-cn-shanghai.aliyuncs.com/img/image-20220601183741-iewypl2.png" srcset="/img/loading.gif" lazyload style="zoom: 50%;" />



<p>Encoder 是一个常规的 RNN，将隐状态输入进 Decoder 中（如果是多层 RNN 则将最后一层的 RNN 最后一个时刻的隐状态的输出作为 Decoder 的输入），也就是将输入的序列信息编码进这个隐状态中；Decoder 的设计可以有几种选择，比如上面图所示的，第一个时刻接受 encoder 的隐状态和 <code>&lt;bos&gt;</code> token，然后后面和一般的 RNN 差不多，另外一种就是在每个时刻都将 Decoder 输出的隐状态和每个时刻的序列同时作为输入，如下图：</p>
<img src="https://picgo-wutao.oss-cn-shanghai.aliyuncs.com/img/image-20220601185525-2kz5uix.png" srcset="/img/loading.gif" lazyload style="zoom:67%;" />



<p>Decoder 预测就是将上一个时刻的输出作为下一个时刻的输入来生成序列。注意，由于 Encoder 可以看到整个序列，所以也可以使用之前讲过的双向 RNN 作为 Encoder（Encoder 起到一个特征提取的作用）。</p>
<h4 id="seq2seq-实现"><a href="#seq2seq-实现" class="headerlink" title="seq2seq 实现"></a>seq2seq 实现</h4><h5 id="Encoder"><a href="#Encoder" class="headerlink" title="Encoder"></a>Encoder</h5><p>在每个时间步中，Encoder 都是将输入 token 的特征向量 $x_t$ 和之前一个时间步的隐藏状态$h_{t-1}$ 转化为当前的隐藏状态 $h_t$ ，可以使用一个函数来表示：</p>
<p>$$<br>h_t &#x3D; f(x_t,h_{t-1})<br>$$</p>
<p>一般来讲，encoder 通过一个自定义的函数将所有时间步的隐藏状态转化为一个 context 变量：</p>
<p>$$<br>c&#x3D;q(h_1,…,h_T)<br>$$</p>
<p>如果 $q(h_1,…,h_T)&#x3D;h_T$ ，那么就是上面说的那种情况，context 变量为最后一层最后一个时间步的隐藏状态。</p>
<p>Encoder 和一般的 RNN 不同的地方在于，其输入序列先要进入一个 <strong>embedding</strong> 层，得到每个特征新的 embedding 向量，这个操作的目的是减少特征的维度（常规的 RNN 输入的token 的特征向量是一个 onehot 向量，其长度是词汇表的长度，如果不是以字符作为 token 的话，有些时候数据集中的词汇可能很多），这个 embedding 层学习的权重矩阵的大小为：（输入的词汇表长度，<code>vocab_size</code>*每个token的特征向量长度<code>embed_size</code>），其余的和 RNN 一样，这里使用 GRU 来实现 Encoder：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> collections<br><span class="hljs-keyword">import</span> math<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><span class="hljs-keyword">from</span> d2l <span class="hljs-keyword">import</span> torch <span class="hljs-keyword">as</span> d2l<br><br><span class="hljs-comment">#@save</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Seq2SeqEncoder</span>(d2l.Encoder):<br>    <span class="hljs-string">&quot;&quot;&quot;The RNN encoder for sequence to sequence learning.&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, vocab_size, embed_size, num_hiddens, num_layers,</span><br><span class="hljs-params">                 dropout=<span class="hljs-number">0</span>, **kwargs</span>):<br>        <span class="hljs-built_in">super</span>(Seq2SeqEncoder, self).__init__(**kwargs)<br>        <span class="hljs-comment"># Embedding layer</span><br>        self.embedding = nn.Embedding(vocab_size, embed_size)<br>        self.rnn = nn.GRU(embed_size, num_hiddens, num_layers,<br>                          dropout=dropout)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, X, *args</span>):<br>        <span class="hljs-comment"># The output `X` shape: (`batch_size`, `num_steps`, `embed_size`)</span><br>        X = self.embedding(X)<br>        <span class="hljs-comment"># In RNN models, the first axis corresponds to time steps</span><br>        X = X.permute(<span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">2</span>)<br>        <span class="hljs-comment"># When state is not mentioned, it defaults to zeros</span><br>        output, state = self.rnn(X)<br>        <span class="hljs-comment"># `output` shape: (`num_steps`, `batch_size`, `num_hiddens`)</span><br>        <span class="hljs-comment"># `state` shape: (`num_layers`, `batch_size`, `num_hiddens`)</span><br>        <span class="hljs-keyword">return</span> output, state<br></code></pre></td></tr></table></figure>

<p><code>torch.permute</code> 返回按照指定维度重新排列的原始 tensor 的 view，这里的操作就是将第0个维度（batch_size）和第一个维度（num_steps）对调，保证时间步在第一个维度；验证一下输出：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python">encoder = Seq2SeqEncoder(vocab_size=<span class="hljs-number">10</span>, embed_size=<span class="hljs-number">8</span>, num_hiddens=<span class="hljs-number">16</span>,<br>                         num_layers=<span class="hljs-number">2</span>)<br>encoder.<span class="hljs-built_in">eval</span>()<br>X = torch.zeros((<span class="hljs-number">4</span>, <span class="hljs-number">7</span>), dtype=torch.long)<span class="hljs-comment">##batch size 为 4，时间步为 7</span><br>output, state = encoder(X)<br>output.shape,state.shape<br><br>(torch.Size([<span class="hljs-number">7</span>, <span class="hljs-number">4</span>, <span class="hljs-number">16</span>]), torch.Size([<span class="hljs-number">2</span>, <span class="hljs-number">4</span>, <span class="hljs-number">16</span>]))<br></code></pre></td></tr></table></figure>

<p>输出的维度（<strong>也就是最后一层的所有时间步的隐状态</strong>）为（时间步*批量大小*隐藏单元的数量），输出的隐藏状态的维度（<strong>也就是所有层最后一个时间步的隐藏状态</strong>）为（隐藏层数*批量大小*隐藏单元数量）。</p>
<h5 id="Decoder"><a href="#Decoder" class="headerlink" title="Decoder"></a>Decoder</h5><p>对于 decoder，这里使用的是第二种方法，也就是在每个时间步都将 encoder 的输出 context 变量和当前的输入 concatenated 起来：</p>
<img src="https://picgo-wutao.oss-cn-shanghai.aliyuncs.com/image-20220601185525-2kz5uix.png" srcset="/img/loading.gif" lazyload style="zoom:50%;" />



<p>需要注意，由于使用 encoder 的最后一个时间步的隐藏状态来初始化 decoder 的隐藏状态，所以 encoder 和 decoder 的隐藏层数量和隐藏层大小应该是一样的；最后使用一个全连接层来转化输出的隐藏状态得到最终的输出：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Seq2SeqDecoder</span>(d2l.Decoder):<br>    <span class="hljs-string">&quot;&quot;&quot;The RNN decoder for sequence to sequence learning.&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, vocab_size, embed_size, num_hiddens, num_layers,</span><br><span class="hljs-params">                 dropout=<span class="hljs-number">0</span>, **kwargs</span>):<br>        <span class="hljs-built_in">super</span>(Seq2SeqDecoder, self).__init__(**kwargs)<br>        self.embedding = nn.Embedding(vocab_size, embed_size)<br>        self.rnn = nn.GRU(embed_size + num_hiddens, num_hiddens, num_layers,<br>                          dropout=dropout)<br>        self.dense = nn.Linear(num_hiddens, vocab_size)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">init_state</span>(<span class="hljs-params">self, enc_outputs, *args</span>):<br>        <span class="hljs-keyword">return</span> enc_outputs[<span class="hljs-number">1</span>]<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, X, state</span>):<br>        <span class="hljs-comment"># The output `X` shape: (`num_steps`, `batch_size`, `embed_size`)</span><br>        X = self.embedding(X).permute(<span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">2</span>)<br>        <span class="hljs-comment"># Broadcast `context` so it has the same `num_steps` as `X`</span><br>        context = state[-<span class="hljs-number">1</span>].repeat(X.shape[<span class="hljs-number">0</span>], <span class="hljs-number">1</span>, <span class="hljs-number">1</span>)<br>        X_and_context = torch.cat((X, context), <span class="hljs-number">2</span>)<br>        output, state = self.rnn(X_and_context, state)<br>        output = self.dense(output).permute(<span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">2</span>)<span class="hljs-comment">##重新将batch size 放到第二个维度</span><br>        <span class="hljs-comment"># `output` shape: (`batch_size`, `num_steps`, `vocab_size`)</span><br>        <span class="hljs-comment"># `state` shape: (`num_layers`, `batch_size`, `num_hiddens`)</span><br>        <span class="hljs-keyword">return</span> output, state<br></code></pre></td></tr></table></figure>

<p><code>state[-1].repeat(X.shape[0], 1, 1)</code> 就是取 <code>state</code> 的最后一个（最后一个时间步的最后一层的隐藏状态），然后重复 decoder 输入的时间步长度的次数，以便于直接和 decoder 的输入连接。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python">decoder = Seq2SeqDecoder(vocab_size=<span class="hljs-number">10</span>, embed_size=<span class="hljs-number">8</span>, num_hiddens=<span class="hljs-number">16</span>,<br>                         num_layers=<span class="hljs-number">2</span>)<br>decoder.<span class="hljs-built_in">eval</span>()<br>state = decoder.init_state(encoder(X))<br>output, state = decoder(X, state)<br>output.shape, state.shape<br><br>(torch.Size([<span class="hljs-number">4</span>, <span class="hljs-number">7</span>, <span class="hljs-number">10</span>]), torch.Size([<span class="hljs-number">2</span>, <span class="hljs-number">4</span>, <span class="hljs-number">16</span>]))<br></code></pre></td></tr></table></figure>

<p>目前的 Seq2seq 的架构为：</p>
<img src="https://picgo-wutao.oss-cn-shanghai.aliyuncs.com/image-20220603165016-m2hgj66.png" srcset="/img/loading.gif" lazyload style="zoom:50%;" />

<h5 id="Loss-函数"><a href="#Loss-函数" class="headerlink" title="Loss 函数"></a>Loss 函数</h5><p>由于之前为了使得一个批量中的序列长度一样，在较短序列的末尾添加了<code>&lt;pad&gt;</code> token，但是在计算 loss 的时候这些 <code>&lt;pad&gt;</code> 应该被排除（依据之前保留的 <code>valid_length</code> 参数）：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#@save</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">sequence_mask</span>(<span class="hljs-params">X, valid_len, value=<span class="hljs-number">0</span></span>):<br>    <span class="hljs-string">&quot;&quot;&quot;Mask irrelevant entries in sequences.&quot;&quot;&quot;</span><br>    maxlen = X.size(<span class="hljs-number">1</span>)<br>    mask = torch.arange((maxlen), dtype=torch.float32,<br>                        device=X.device)[<span class="hljs-literal">None</span>, :] &lt; valid_len[:, <span class="hljs-literal">None</span>]<br>    X[~mask] = value<br>    <span class="hljs-keyword">return</span> X<br><br>X = torch.tensor([[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>], [<span class="hljs-number">5</span>, <span class="hljs-number">6</span>, <span class="hljs-number">7</span>, <span class="hljs-number">8</span>]])<br>sequence_mask(X, torch.tensor([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>]))<br><br>tensor([[<span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>],<br>        [<span class="hljs-number">5</span>, <span class="hljs-number">6</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>]])<br></code></pre></td></tr></table></figure>

<p><code>[None, :]</code> 表示增加一个 0 维度，<code>[:, None]</code> 表示增加一个 1 维度：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs python">torch.tensor([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>]).shape,torch.tensor([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>])[:, <span class="hljs-literal">None</span>].shape<br>(torch.Size([<span class="hljs-number">2</span>]), torch.Size([<span class="hljs-number">2</span>, <span class="hljs-number">1</span>]))<br><br>torch.tensor([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>])[:, <span class="hljs-literal">None</span>]<br>tensor([[<span class="hljs-number">1</span>],<br>        [<span class="hljs-number">2</span>]])<br><br>torch.arange(<span class="hljs-number">4</span>).shape,torch.arange(<span class="hljs-number">4</span>)[<span class="hljs-literal">None</span>, :].shape<br>(torch.Size([<span class="hljs-number">4</span>]), torch.Size([<span class="hljs-number">1</span>, <span class="hljs-number">4</span>]))<br><br>torch.arange(<span class="hljs-number">4</span>)[<span class="hljs-literal">None</span>, :]<br>tensor([[<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>]])<br><br><span class="hljs-comment">##将torch.arange(4)[None, :]的第一个维度广播成2维，从而与torch.tensor([1, 2])[:, None]进行逻辑运算</span><br>torch.arange(<span class="hljs-number">4</span>)[<span class="hljs-literal">None</span>, :] &lt; torch.tensor([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>])[:, <span class="hljs-literal">None</span>]<br>tensor([[ <span class="hljs-literal">True</span>, <span class="hljs-literal">False</span>, <span class="hljs-literal">False</span>, <span class="hljs-literal">False</span>],<br>        [ <span class="hljs-literal">True</span>,  <span class="hljs-literal">True</span>, <span class="hljs-literal">False</span>, <span class="hljs-literal">False</span>]])<br><br>a = torch.arange(<span class="hljs-number">4</span>)[<span class="hljs-literal">None</span>, :] &lt; torch.tensor([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>])[:, <span class="hljs-literal">None</span>]<br>X = torch.tensor([[<span class="hljs-number">0</span>, <span class="hljs-number">9</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>], [<span class="hljs-number">5</span>, <span class="hljs-number">6</span>, <span class="hljs-number">7</span>, <span class="hljs-number">8</span>]])<br>X<br>tensor([[<span class="hljs-number">0</span>, <span class="hljs-number">9</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>],<br>        [<span class="hljs-number">5</span>, <span class="hljs-number">6</span>, <span class="hljs-number">7</span>, <span class="hljs-number">8</span>]])<br><br>X[~a]<span class="hljs-comment">##哪些是False ~ 是取反操作</span><br>tensor([<span class="hljs-number">9</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">7</span>, <span class="hljs-number">8</span>])<br><br>~a<br>tensor([[<span class="hljs-literal">False</span>,  <span class="hljs-literal">True</span>,  <span class="hljs-literal">True</span>,  <span class="hljs-literal">True</span>],<br>        [<span class="hljs-literal">False</span>, <span class="hljs-literal">False</span>,  <span class="hljs-literal">True</span>,  <span class="hljs-literal">True</span>]])<br></code></pre></td></tr></table></figure>

<p>接下来就可以更改之前的交叉熵 loss 来考虑这些 padding 的影响：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#@save</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">MaskedSoftmaxCELoss</span>(nn.CrossEntropyLoss):<span class="hljs-comment">#继承CrossEntropyLoss</span><br>    <span class="hljs-string">&quot;&quot;&quot;The softmax cross-entropy loss with masks.&quot;&quot;&quot;</span><br>    <span class="hljs-comment"># `pred` shape: (`batch_size`, `num_steps`, `vocab_size`)</span><br>    <span class="hljs-comment"># `label` shape: (`batch_size`, `num_steps`)</span><br>    <span class="hljs-comment"># `valid_len` shape: (`batch_size`,)</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, pred, label, valid_len</span>):<br>        weights = torch.ones_like(label)<br>        weights = sequence_mask(weights, valid_len)<br>        self.reduction=<span class="hljs-string">&#x27;none&#x27;</span><br>        unweighted_loss = <span class="hljs-built_in">super</span>().forward(pred.permute(<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, <span class="hljs-number">1</span>), label)<br>        weighted_loss = (unweighted_loss * weights).mean(dim=<span class="hljs-number">1</span>)<br>        <span class="hljs-keyword">return</span> weighted_loss<br><br>pred = torch.ones(<span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">10</span>)<br>pred<br>tensor([[[<span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>],<br>         [<span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>],<br>         [<span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>],<br>         [<span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>]],<br><br>        [[<span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>],<br>         [<span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>],<br>         [<span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>],<br>         [<span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>]],<br><br>        [[<span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>],<br>         [<span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>],<br>         [<span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>],<br>         [<span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>]]])<br><br>label = torch.ones((<span class="hljs-number">3</span>, <span class="hljs-number">4</span>), dtype=torch.long)<br>label<br>tensor([[<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>],<br>        [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>],<br>        [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>]])<br><br>valid_len = torch.tensor([<span class="hljs-number">4</span>, <span class="hljs-number">2</span>, <span class="hljs-number">0</span>])<br>valid_len<br>tensor([<span class="hljs-number">4</span>, <span class="hljs-number">2</span>, <span class="hljs-number">0</span>])<br><br>weights = torch.ones_like(label)<br>weights = sequence_mask(weights, valid_len)<br>weights<br>tensor([[<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>],<br>        [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>],<br>        [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>]])<br><br>loss = nn.CrossEntropyLoss(reduction = <span class="hljs-string">&quot;none&quot;</span>)<br>unweighted_loss = loss(pred.permute(<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, <span class="hljs-number">1</span>), label)<br>unweighted_loss<br>tensor([[<span class="hljs-number">2.3026</span>, <span class="hljs-number">2.3026</span>, <span class="hljs-number">2.3026</span>, <span class="hljs-number">2.3026</span>],<br>        [<span class="hljs-number">2.3026</span>, <span class="hljs-number">2.3026</span>, <span class="hljs-number">2.3026</span>, <span class="hljs-number">2.3026</span>],<br>        [<span class="hljs-number">2.3026</span>, <span class="hljs-number">2.3026</span>, <span class="hljs-number">2.3026</span>, <span class="hljs-number">2.3026</span>]])<br><br>unweighted_loss * weights<br>tensor([[<span class="hljs-number">2.3026</span>, <span class="hljs-number">2.3026</span>, <span class="hljs-number">2.3026</span>, <span class="hljs-number">2.3026</span>],<br>        [<span class="hljs-number">2.3026</span>, <span class="hljs-number">2.3026</span>, <span class="hljs-number">0.0000</span>, <span class="hljs-number">0.0000</span>],<br>        [<span class="hljs-number">0.0000</span>, <span class="hljs-number">0.0000</span>, <span class="hljs-number">0.0000</span>, <span class="hljs-number">0.0000</span>]])<br><br>(unweighted_loss * weights).mean(dim=<span class="hljs-number">1</span>)<br>tensor([<span class="hljs-number">2.3026</span>, <span class="hljs-number">1.1513</span>, <span class="hljs-number">0.0000</span>])<br></code></pre></td></tr></table></figure>

<h5 id="训练-1"><a href="#训练-1" class="headerlink" title="训练"></a>训练</h5><p>训练使用的方法：</p>
<img src="https://picgo-wutao.oss-cn-shanghai.aliyuncs.com/image-20220601185525-2kz5uix.png" srcset="/img/loading.gif" lazyload style="zoom:50%;" />



<p>这个过程叫做 <em>teacher forcing</em>，也就是每次不使用上一个时间步的输出作为下一个时间步的输入，而是直接使用训练数据中相应的输入，这样即使在某一步预测错误也不影响下一步的输入：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#@save</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">train_seq2seq</span>(<span class="hljs-params">net, data_iter, lr, num_epochs, tgt_vocab, device</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;Train a model for sequence to sequence.&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">xavier_init_weights</span>(<span class="hljs-params">m</span>):<br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">type</span>(m) == nn.Linear:<br>            nn.init.xavier_uniform_(m.weight)<br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">type</span>(m) == nn.GRU:<br>            <span class="hljs-keyword">for</span> param <span class="hljs-keyword">in</span> m._flat_weights_names:<br>                <span class="hljs-keyword">if</span> <span class="hljs-string">&quot;weight&quot;</span> <span class="hljs-keyword">in</span> param:<br>                    nn.init.xavier_uniform_(m._parameters[param])<br>    net.apply(xavier_init_weights)<br>    net.to(device)<br>    optimizer = torch.optim.Adam(net.parameters(), lr=lr)<br>    loss = MaskedSoftmaxCELoss()<br>    net.train()<br>    animator = d2l.Animator(xlabel=<span class="hljs-string">&#x27;epoch&#x27;</span>, ylabel=<span class="hljs-string">&#x27;loss&#x27;</span>,<br>                            xlim=[<span class="hljs-number">10</span>, num_epochs])<br>    <span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_epochs):<br>        timer = d2l.Timer()<br>        metric = d2l.Accumulator(<span class="hljs-number">2</span>)  <span class="hljs-comment"># Sum of training loss, no. of tokens</span><br>        <span class="hljs-keyword">for</span> batch <span class="hljs-keyword">in</span> data_iter:<br>            optimizer.zero_grad()<br>            X, X_valid_len, Y, Y_valid_len = [x.to(device) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> batch]<br>            bos = torch.tensor([tgt_vocab[<span class="hljs-string">&#x27;&lt;bos&gt;&#x27;</span>]] * Y.shape[<span class="hljs-number">0</span>],<br>                               device=device).reshape(-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>)<br>            dec_input = torch.cat([bos, Y[:, :-<span class="hljs-number">1</span>]], <span class="hljs-number">1</span>)  <span class="hljs-comment"># Teacher forcing</span><br>            Y_hat, _ = net(X, dec_input, X_valid_len)<br>            l = loss(Y_hat, Y, Y_valid_len)<br>            l.<span class="hljs-built_in">sum</span>().backward()  <span class="hljs-comment"># Make the loss scalar for `backward`</span><br>            d2l.grad_clipping(net, <span class="hljs-number">1</span>)<br>            num_tokens = Y_valid_len.<span class="hljs-built_in">sum</span>()<br>            optimizer.step()<br>            <span class="hljs-keyword">with</span> torch.no_grad():<br>                metric.add(l.<span class="hljs-built_in">sum</span>(), num_tokens)<br>        <span class="hljs-keyword">if</span> (epoch + <span class="hljs-number">1</span>) % <span class="hljs-number">10</span> == <span class="hljs-number">0</span>:<br>            animator.add(epoch + <span class="hljs-number">1</span>, (metric[<span class="hljs-number">0</span>] / metric[<span class="hljs-number">1</span>],))<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;loss <span class="hljs-subst">&#123;metric[<span class="hljs-number">0</span>] / metric[<span class="hljs-number">1</span>]:<span class="hljs-number">.3</span>f&#125;</span>, <span class="hljs-subst">&#123;metric[<span class="hljs-number">1</span>] / timer.stop():<span class="hljs-number">.1</span>f&#125;</span> &#x27;</span><br>          <span class="hljs-string">f&#x27;tokens/sec on <span class="hljs-subst">&#123;<span class="hljs-built_in">str</span>(device)&#125;</span>&#x27;</span>)<br><br>embed_size, num_hiddens, num_layers, dropout = <span class="hljs-number">32</span>, <span class="hljs-number">32</span>, <span class="hljs-number">2</span>, <span class="hljs-number">0.1</span><br>batch_size, num_steps = <span class="hljs-number">64</span>, <span class="hljs-number">10</span><br>lr, num_epochs, device = <span class="hljs-number">0.005</span>, <span class="hljs-number">300</span>, d2l.try_gpu()<br><br>torch.set_num_threads(<span class="hljs-number">30</span>)<span class="hljs-comment">#限制线程</span><br>train_iter, src_vocab, tgt_vocab = d2l.load_data_nmt(batch_size, num_steps)<br>encoder = Seq2SeqEncoder(<br>    <span class="hljs-built_in">len</span>(src_vocab), embed_size, num_hiddens, num_layers, dropout)<br>decoder = Seq2SeqDecoder(<br>    <span class="hljs-built_in">len</span>(tgt_vocab), embed_size, num_hiddens, num_layers, dropout)<br>net = d2l.EncoderDecoder(encoder, decoder)<br>train_seq2seq(net, train_iter, lr, num_epochs, tgt_vocab, device)<br></code></pre></td></tr></table></figure>

<img src="https://picgo-wutao.oss-cn-shanghai.aliyuncs.com/image-20220603183828-43ixgq6.png" srcset="/img/loading.gif" lazyload alt="" style="zoom:50%;" />

<h5 id="预测-1"><a href="#预测-1" class="headerlink" title="预测"></a>预测</h5><p>预测的架构如下，和 Decoder 训练时不同的地方在于：除了第一个时间步输入是 <code>&lt;bos&gt;</code> 的token 外，其他的时间步的输入是前一个时间步的输出（取概率最大的）：</p>
<img src="https://picgo-wutao.oss-cn-shanghai.aliyuncs.com/image-20220603183910-cz3hxrq.png" srcset="/img/loading.gif" lazyload style="zoom: 67%;" />

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#@save</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">predict_seq2seq</span>(<span class="hljs-params">net, src_sentence, src_vocab, tgt_vocab, num_steps,</span><br><span class="hljs-params">                    device, save_attention_weights=<span class="hljs-literal">False</span></span>):<br>    <span class="hljs-string">&quot;&quot;&quot;Predict for sequence to sequence.&quot;&quot;&quot;</span><br>    <span class="hljs-comment"># Set `net` to eval mode for inference</span><br>    net.<span class="hljs-built_in">eval</span>()<br>    src_tokens = src_vocab[src_sentence.lower().split(<span class="hljs-string">&#x27; &#x27;</span>)] + [<br>        src_vocab[<span class="hljs-string">&#x27;&lt;eos&gt;&#x27;</span>]]<br>    enc_valid_len = torch.tensor([<span class="hljs-built_in">len</span>(src_tokens)], device=device)<br>    src_tokens = d2l.truncate_pad(src_tokens, num_steps, src_vocab[<span class="hljs-string">&#x27;&lt;pad&gt;&#x27;</span>])<br>    <span class="hljs-comment"># Add the batch axis</span><br>    enc_X = torch.unsqueeze(<br>        torch.tensor(src_tokens, dtype=torch.long, device=device), dim=<span class="hljs-number">0</span>)<br>    enc_outputs = net.encoder(enc_X, enc_valid_len)<br>    dec_state = net.decoder.init_state(enc_outputs, enc_valid_len)<br>    <span class="hljs-comment"># Add the batch axis</span><br>    dec_X = torch.unsqueeze(torch.tensor(<br>        [tgt_vocab[<span class="hljs-string">&#x27;&lt;bos&gt;&#x27;</span>]], dtype=torch.long, device=device), dim=<span class="hljs-number">0</span>)<br>    output_seq, attention_weight_seq = [], []<br>    <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_steps):<br>        Y, dec_state = net.decoder(dec_X, dec_state)<br>        <span class="hljs-comment"># We use the token with the highest prediction likelihood as the input</span><br>        <span class="hljs-comment"># of the decoder at the next time step</span><br>        dec_X = Y.argmax(dim=<span class="hljs-number">2</span>)<br>        pred = dec_X.squeeze(dim=<span class="hljs-number">0</span>).<span class="hljs-built_in">type</span>(torch.int32).item()<br>        <span class="hljs-comment"># Save attention weights (to be covered later)</span><br>        <span class="hljs-keyword">if</span> save_attention_weights:<br>            attention_weight_seq.append(net.decoder.attention_weights)<br>        <span class="hljs-comment"># Once the end-of-sequence token is predicted, the generation of the</span><br>        <span class="hljs-comment"># output sequence is complete</span><br>        <span class="hljs-keyword">if</span> pred == tgt_vocab[<span class="hljs-string">&#x27;&lt;eos&gt;&#x27;</span>]:<br>            <span class="hljs-keyword">break</span><br>        output_seq.append(pred)<br>    <span class="hljs-keyword">return</span> <span class="hljs-string">&#x27; &#x27;</span>.join(tgt_vocab.to_tokens(output_seq)), attention_weight_seq<br></code></pre></td></tr></table></figure>

<h4 id="评估函数"><a href="#评估函数" class="headerlink" title="评估函数"></a>评估函数</h4><p>在机器翻译中广泛使用的评估函数为 BLUE（Bilingual Evaluation Understudy）：</p>
<img src="https://picgo-wutao.oss-cn-shanghai.aliyuncs.com/image-20220603185940-n4rj7s1.png" srcset="/img/loading.gif" lazyload style="zoom:50%;" />

<p>对于预测序列中的任意 n-gram（gram 表示词汇），BLEU 评估是否这个 n-gram 出现在标签序列中；设 $p_n$ 为 n-gram 的精度，也就是在预测和标签序列中匹配的 n-gram 的数量处于预测序列中的 n-gram 的数量，比如上面那张图里面的例子：1-gram 有 A, B, C, D, E, F 这些 1-gram 中和标签序列匹配的有 A, B, C, D 一共 4 个，预测序列的长度为 5 ，因此 p1 为 4&#x2F;5；同样的 2-gram 有 AB, BC, CD, DE, EF，和标签序列匹配的有 AB, BC, CD 一共 3 个，因此 p2 为 3&#x2F;4，同理 3-gram 只有 BCD 是匹配的，所以为 1&#x2F;3 。</p>
<p>由于更长的 gram 匹配的难度越大，因此 BLEU 给与大的 n-gram 比较高的权重（$p_n^{1&#x2F;2^n}$，由于 $p_n$ 是小于1 的，所以 n 越大，$1&#x2F;2^n$ 又是小于1的，$1&#x2F;2^n$ 越小，整体就越大）:</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs r"><span class="hljs-operator">&gt;</span> tt <span class="hljs-operator">&lt;-</span> <span class="hljs-keyword">function</span><span class="hljs-punctuation">(</span>x<span class="hljs-punctuation">)</span><span class="hljs-punctuation">&#123;</span><span class="hljs-number">0.2</span><span class="hljs-operator">^</span><span class="hljs-punctuation">(</span><span class="hljs-number">1</span><span class="hljs-operator">/</span><span class="hljs-punctuation">(</span><span class="hljs-number">2</span><span class="hljs-operator">^</span>x<span class="hljs-punctuation">)</span><span class="hljs-punctuation">)</span><span class="hljs-punctuation">&#125;</span><br><span class="hljs-operator">&gt;</span> s <span class="hljs-operator">&lt;-</span> tt<span class="hljs-punctuation">(</span><span class="hljs-built_in">c</span><span class="hljs-punctuation">(</span><span class="hljs-number">1</span><span class="hljs-operator">:</span><span class="hljs-number">6</span><span class="hljs-punctuation">)</span><span class="hljs-punctuation">)</span><br><span class="hljs-operator">&gt;</span> s<br><span class="hljs-punctuation">[</span><span class="hljs-number">1</span><span class="hljs-punctuation">]</span> <span class="hljs-number">0.4472136</span> <span class="hljs-number">0.6687403</span> <span class="hljs-number">0.8177654</span> <span class="hljs-number">0.9043038</span> <span class="hljs-number">0.9509489</span> <span class="hljs-number">0.9751661</span><br></code></pre></td></tr></table></figure>

<p>同时由于短的 gram 比较好匹配，会得到较高的 $p_n$ 值，因此 BLEU 给短的预测有个惩罚（前面的 min 项，当预测的比较短，会使得 min 项小于0 ，因此 exp 后的值也会比较小），比如：标签序列是 A, B, C, D, E 但是预测序列是 A, B，那么得到的 p1 &#x3D; p2 &#x3D; 1，但是计算前面的项时得到的惩罚因子为 exp(1-6&#x2F;2)&#x3D;0.14。代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">bleu</span>(<span class="hljs-params">pred_seq, label_seq, k</span>):  <span class="hljs-comment">#@save</span><br>    <span class="hljs-string">&quot;&quot;&quot;Compute the BLEU.&quot;&quot;&quot;</span><br>    pred_tokens, label_tokens = pred_seq.split(<span class="hljs-string">&#x27; &#x27;</span>), label_seq.split(<span class="hljs-string">&#x27; &#x27;</span>)<br>    len_pred, len_label = <span class="hljs-built_in">len</span>(pred_tokens), <span class="hljs-built_in">len</span>(label_tokens)<br>    score = math.exp(<span class="hljs-built_in">min</span>(<span class="hljs-number">0</span>, <span class="hljs-number">1</span> - len_label / len_pred))<br>    <span class="hljs-keyword">for</span> n <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, k + <span class="hljs-number">1</span>):<br>        num_matches, label_subs = <span class="hljs-number">0</span>, collections.defaultdict(<span class="hljs-built_in">int</span>)<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(len_label - n + <span class="hljs-number">1</span>):<br>            label_subs[<span class="hljs-string">&#x27; &#x27;</span>.join(label_tokens[i: i + n])] += <span class="hljs-number">1</span><br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(len_pred - n + <span class="hljs-number">1</span>):<br>            <span class="hljs-keyword">if</span> label_subs[<span class="hljs-string">&#x27; &#x27;</span>.join(pred_tokens[i: i + n])] &gt; <span class="hljs-number">0</span>:<br>                num_matches += <span class="hljs-number">1</span><br>                label_subs[<span class="hljs-string">&#x27; &#x27;</span>.join(pred_tokens[i: i + n])] -= <span class="hljs-number">1</span><br>        score *= math.<span class="hljs-built_in">pow</span>(num_matches / (len_pred - n + <span class="hljs-number">1</span>), math.<span class="hljs-built_in">pow</span>(<span class="hljs-number">0.5</span>, n))<br>    <span class="hljs-keyword">return</span> score<br></code></pre></td></tr></table></figure>

<p>计算 BLEU ：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python">engs = [<span class="hljs-string">&#x27;go .&#x27;</span>, <span class="hljs-string">&quot;i lost .&quot;</span>, <span class="hljs-string">&#x27;he\&#x27;s calm .&#x27;</span>, <span class="hljs-string">&#x27;i\&#x27;m home .&#x27;</span>]<br>fras = [<span class="hljs-string">&#x27;va !&#x27;</span>, <span class="hljs-string">&#x27;j\&#x27;ai perdu .&#x27;</span>, <span class="hljs-string">&#x27;il est calme .&#x27;</span>, <span class="hljs-string">&#x27;je suis chez moi .&#x27;</span>]<br><span class="hljs-keyword">for</span> eng, fra <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(engs, fras):<br>    translation, attention_weight_seq = predict_seq2seq(<br>        net, eng, src_vocab, tgt_vocab, num_steps, device)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;<span class="hljs-subst">&#123;eng&#125;</span> =&gt; <span class="hljs-subst">&#123;translation&#125;</span>, bleu <span class="hljs-subst">&#123;bleu(translation, fra, k=<span class="hljs-number">2</span>):<span class="hljs-number">.3</span>f&#125;</span>&#x27;</span>)<br><br>go . =&gt; va !, bleu <span class="hljs-number">1.000</span><br>i lost . =&gt; j<span class="hljs-string">&#x27;ai perdu ., bleu 1.000</span><br><span class="hljs-string">he&#x27;</span>s calm . =&gt; il est riche paresseux, bleu <span class="hljs-number">0.537</span><br>i<span class="hljs-string">&#x27;m home . =&gt; je suis chez moi ., bleu 1.000</span><br></code></pre></td></tr></table></figure>

<h3 id="束搜索"><a href="#束搜索" class="headerlink" title="束搜索"></a>束搜索</h3><p>前面实现的 Seq2seq 实际上使用了贪婪算法，也就是在每一步中都只关注目前最好的结果，在 seq2seq2 模型就是在每个时间点取预测概率最大的词作为下一个时间点的输入，但是贪婪搜索得到的结果不总是最好的，比如下面两个例子：</p>
<img src="https://picgo-wutao.oss-cn-shanghai.aliyuncs.com/image-20220606175247-wn7ho2x.png" srcset="/img/loading.gif" lazyload style="zoom:50%;" />

<p>要想得到最好的结果只能使用穷举法，也就是考察所有的序列，找到概率最高的序列；但是如果有 n 个词，时间步为 T ，那么需要比较的序列就有 $n^T$ 个，这个时间复杂度在计算上是不可行的。</p>
<p>束搜索则是采取了一种居中的方法，在每个时间点上考虑 k 中可能：</p>
<img src="https://picgo-wutao.oss-cn-shanghai.aliyuncs.com/image-20220606175755-h937bef.png" srcset="/img/loading.gif" lazyload style="zoom: 50%;" />

<p>比如上面的情况：词汇表中有 5 个词，输入句子的开始，在第一步预测的 5 个词的概率中取最高的两个，分别基于这两个进行下一个时间点的预测，又可以得到 10 个概率值，在这 10 个里面再取 2 个最高的，如此下去，最终就可以得到一系列的候选序列（这里是两个），然后基于下面的打分函数选择得分最高的序列作为最终的输出序列：</p>
<img src="https://picgo-wutao.oss-cn-shanghai.aliyuncs.com/image-20220606180238-pwvgyzr.png" srcset="/img/loading.gif" lazyload style="zoom:50%;" />

<p>L 表示候选序列的长度，对于短的序列得到的概率就越大，因此对于短的序列（为什么会出现不一样的长度，因为可能某个序列预测时提前出现 <code>&lt;eos&gt;</code>，可以想象为平行宇宙）有个惩罚（或者说对长的序列有奖励，因为 <code>log(p)</code> 是负的，负值除以越大的值结果就越大）。另外束搜索的复杂度为 $knT$ ，比穷举法要小得多。</p>
<p>参考资料：</p>
<ul>
<li>动手学深度学习</li>
<li><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1Wv411h7kN?p=40">(强推)李宏毅2021&#x2F;2022春机器学习课程_哔哩哔哩_bilibili</a></li>
</ul>

              
            </div>
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" class="category-chain-item">深度学习</a>
  
  

      </span>
    
  
</span>

    </div>
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">#深度学习</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>循环神经网络</div>
      <div>http://example.com/2022/06/01/RNN/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>Wu Tao</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2022年6月1日</div>
        </div>
      
      
      <div class="license-meta-item">
        <div>许可协议</div>
        <div>
          
            
            
              <a target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
              <span class="hint--top hint--rounded" aria-label="BY - 署名">
                <i class="iconfont icon-by"></i>
              </span>
              </a>
            
          
        </div>
      </div>
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2022/06/10/hello-world/" title="Hello World">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">Hello World</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2022/05/07/paper_MTGCN/" title="使用多任务图卷积神经网络改进癌症驱动基因识别">
                        <span class="hidden-mobile">使用多任务图卷积神经网络改进癌症驱动基因识别</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
  <article id="comments" lazyload>
    
  <div id="waline"></div>
  <script type="text/javascript">
    Fluid.utils.loadComments('#waline', function() {
      Fluid.utils.createCssLink('https://cdn.jsdelivr.net/npm/@waline/client@0.14.8/dist/waline.min.css')
      Fluid.utils.createScript('https://cdn.jsdelivr.net/npm/@waline/client@0.14.8/dist/waline.min.js', function() {
        var options = Object.assign(
          {"serverURL":"https://comments-flax.vercel.app","path":"window.location.pathname","meta":["nick","mail","link"],"requiredMeta":["nick"],"lang":"zh-CN","emoji":["https://cdn.jsdelivr.net/gh/walinejs/emojis/weibo"],"dark":"html[data-user-color-scheme=\"dark\"]","wordLimit":0,"pageSize":10},
          {
            el: '#waline',
            path: window.location.pathname
          }
        )
        Waline.init(options);
        Fluid.utils.waitElementVisible('#waline .vcontent', () => {
          var imgSelector = '#waline .vcontent img:not(.vemoji)';
          Fluid.plugins.imageCaption(imgSelector);
          Fluid.plugins.fancyBox(imgSelector);
        })
      });
    });
  </script>
  <noscript>Please enable JavaScript to view the comments</noscript>


  </article>


          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  


  
  








    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
    <div class="statistics">
  
  

  
    
      <span id="leancloud-site-pv-container" style="display: none">
        总访问量 
        <span id="leancloud-site-pv"></span>
         次
      </span>
    
    
      <span id="leancloud-site-uv-container" style="display: none">
        总访客数 
        <span id="leancloud-site-uv"></span>
         人
      </span>
    
    

  
</div>

  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://cdn.jsdelivr.net/npm/nprogress@0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/nprogress@0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" ></script>
<script  src="https://cdn.jsdelivr.net/npm/bootstrap@4.5.3/dist/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://cdn.jsdelivr.net/npm/typed.js@2.0.11/lib/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  

  

  

  

  

  

  
    
  




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://cdn.jsdelivr.net/npm/tocbot@4.12.2/dist/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      headingSelector : CONFIG.toc.headingSelector || 'h1,h2,h3,h4,h5,h6',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      collapseDepth   : CONFIG.toc.collapseDepth || 0,
      scrollSmooth    : true,
      headingsOffset  : -boardTop
    });
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }
  });
</script>


  <script>
  (function() {
    var enableLang = CONFIG.code_language.enable && CONFIG.code_language.default;
    var enableCopy = CONFIG.copy_btn;
    if (!enableLang && !enableCopy) {
      return;
    }

    function getBgClass(ele) {
      return Fluid.utils.getBackgroundLightness(ele) >= 0 ? 'code-widget-light' : 'code-widget-dark';
    }

    var copyTmpl = '';
    copyTmpl += '<div class="code-widget">';
    copyTmpl += 'LANG';
    copyTmpl += '</div>';
    jQuery('.markdown-body pre').each(function() {
      var $pre = jQuery(this);
      if ($pre.find('code.mermaid').length > 0) {
        return;
      }
      if ($pre.find('span.line').length > 0) {
        return;
      }

      var lang = '';

      if (enableLang) {
        lang = CONFIG.code_language.default;
        if ($pre[0].children.length > 0 && $pre[0].children[0].classList.length >= 2 && $pre.children().hasClass('hljs')) {
          lang = $pre[0].children[0].classList[1];
        } else if ($pre[0].getAttribute('data-language')) {
          lang = $pre[0].getAttribute('data-language');
        } else if ($pre.parent().hasClass('sourceCode') && $pre[0].children.length > 0 && $pre[0].children[0].classList.length >= 2) {
          lang = $pre[0].children[0].classList[1];
          $pre.parent().addClass('code-wrapper');
        } else if ($pre.parent().hasClass('markdown-body') && $pre[0].classList.length === 0) {
          $pre.wrap('<div class="code-wrapper"></div>');
        }
        lang = lang.toUpperCase().replace('NONE', CONFIG.code_language.default);
      }
      $pre.append(copyTmpl.replace('LANG', lang).replace('code-widget">',
        getBgClass($pre[0]) + (enableCopy ? ' code-widget copy-btn" data-clipboard-snippet><i class="iconfont icon-copy"></i>' : ' code-widget">')));

      if (enableCopy) {
        Fluid.utils.createScript('https://cdn.jsdelivr.net/npm/clipboard@2.0.8/dist/clipboard.min.js', function() {
          var clipboard = new window.ClipboardJS('.copy-btn', {
            target: function(trigger) {
              var nodes = trigger.parentNode.childNodes;
              for (var i = 0; i < nodes.length; i++) {
                if (nodes[i].tagName === 'CODE') {
                  return nodes[i];
                }
              }
            }
          });
          clipboard.on('success', function(e) {
            e.clearSelection();
            e.trigger.innerHTML = e.trigger.innerHTML.replace('icon-copy', 'icon-success');
            setTimeout(function() {
              e.trigger.innerHTML = e.trigger.innerHTML.replace('icon-success', 'icon-copy');
            }, 2000);
          });
        });
      }
    });
  })();
</script>


  
<script>
  Fluid.utils.createScript('https://cdn.jsdelivr.net/npm/anchor-js@4.3.0/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));
  });
</script>


  
<script>
  Fluid.utils.createScript('https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  
      <script>
        MathJax = {
          tex    : {
            inlineMath: { '[+]': [['$', '$']] }
          },
          loader : {
            
          },
          options: {
            renderActions: {
              findScript    : [10, doc => {
                document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
                  const display = !!node.type.match(/; *mode=display/);
                  const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
                  const text = document.createTextNode('');
                  node.parentNode.replaceChild(text, node);
                  math.start = { node: text, delim: '', n: 0 };
                  math.end = { node: text, delim: '', n: 0 };
                  doc.math.push(math);
                });
              }, '', false],
              insertedScript: [200, () => {
                document.querySelectorAll('mjx-container').forEach(node => {
                  let target = node.parentNode;
                  if (target.nodeName.toLowerCase() === 'li') {
                    target.parentNode.classList.add('has-jax');
                  }
                });
              }, '', false]
            }
          }
        };
      </script>
    

  <script  src="https://cdn.jsdelivr.net/npm/mathjax@3.1.2/es5/tex-mml-chtml.js" ></script>

  <script  src="/js/local-search.js" ></script>

  <script defer src="/js/leancloud.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
</body>
</html>
